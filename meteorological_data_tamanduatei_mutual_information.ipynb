{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sk\n",
    "import scipy \n",
    "import igraph\n",
    "import ts2vg # Time series to visibility graphs\n",
    "import scipy.spatial.distance as distance\n",
    "import scipy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks para Mutual Information:\n",
    "    1. Gerar redes contendo o mesmo número de arestas da rede Pearson\n",
    "    2. Gerar redes com limiar baseado no maior diâmetro (e backbone associado)\n",
    "    3. Gerar redes com limiar baseado nas maiores (1%) correlações (e backbone associado)\n",
    "    4. Verificar as características de todas as redes e realizar a geração do shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções e Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographical distance between all pairs\n",
    "c = 1;\n",
    "keys = {};\n",
    "for i in range(len(meteorological_time_series)):\n",
    "    for j in range(c,len(meteorological_time_series)):\n",
    "        keys[i,j] = (i,j);\n",
    "    c+=1;\n",
    "geo_dist = (geographical_distance(list(keys.keys()),position));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class threshold():\n",
    "    # Remover arestas com peso abaixo de um dado threshold (valor real)\n",
    "    # entrada: g, flow_threshold\n",
    "    # retorno: g              \n",
    "    def remove_edges(g, flow_threshold):\n",
    "        del_edges = []\n",
    "        for e in g.es():\n",
    "            if e['weight'] < flow_threshold:\n",
    "                del_edges.append(e)\n",
    "        g.delete_edges(del_edges)\n",
    "        return g\n",
    "\n",
    "    # Função que varia o threshold e chama a função acima \n",
    "    # remover as arestas abaixo do threshold e em seguida verifica o diâmetro\n",
    "    # Entrada: g\n",
    "    # Retorno: threshold (valor real) associado ao maior diâmetro da rede\n",
    "    def max_diameter_threshold(g):\n",
    "        max_threshold = max(g.es['weight'])\n",
    "        max_diameter = 0\n",
    "        for t in np.arange(0.1, max_threshold, 0.01):\n",
    "            #print(threshold)\n",
    "            ng = g.copy()\n",
    "            ng = threshold.remove_edges(ng, t)\n",
    "            #print(ng)\n",
    "            diameter = ng.diameter(directed=False)\n",
    "            #print(diameter)\n",
    "            if diameter > max_diameter:\n",
    "                max_diameter = diameter\n",
    "                threshold_max_diameter = t\n",
    "        return threshold_max_diameter\n",
    "\n",
    "def heterogeinity(degree):\n",
    "    power_degree = [] # degree sequence \n",
    "    for i in degree:\n",
    "        power_degree.append(i**2)\n",
    "        hp = ( (sum(power_degree)/len(power_degree))/((sum(degree)/len(degree))**2) )\n",
    "    return(hp)\n",
    "\n",
    "def geographical_distance(adj,pos):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        adj - pares de pontos que correspondem a um ponto (série temporal) disposta no espaço geográfico da \n",
    "        bacia do rio Tamanduateí.\n",
    "        pos - índice (d,j) de cada ponto na matriz que representa o espaço geográfico.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        A distância euclidiana entre os pontos distribuídos na região analisada.\n",
    "    \"\"\"\n",
    "    geo_dist = {}\n",
    "    for i in adj: # i é o par formado pelos grafos 'a' e 'b'\n",
    "        a = pos[i[0]] # busca as coordenadas (i,j) do grafo 'a' no vetor que guarda a posição das séries na matriz\n",
    "        b = pos[i[1]] # busca as coordenadas (i,j) do grafo 'b' no vetor que guarda a posição das séries na matriz\n",
    "        dist = np.sqrt((a[0]-b[0])**2+(a[1]-b[1])**2)\n",
    "        geo_dist[i] = dist\n",
    "    return(geo_dist)\n",
    "\n",
    "def norm(data,dataType):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        data: Lista ou dicionário\n",
    "        dataType: Informa se o dado é do tipo lista (0), ou do tipo dicionário (1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        Valores do vetor data entre o intervalo de 0 e 1.\n",
    "    \n",
    "    \"\"\"\n",
    "    if (dataType == 0):\n",
    "        n = [];\n",
    "        max_value = max(data);\n",
    "        min_value = min(data);\n",
    "        for i in range(len(data)):\n",
    "            n.append((data[i]-min_value)/(max_value - min_value));\n",
    "    else:\n",
    "        n = {};\n",
    "        max_value = max(list(data.values()));\n",
    "        min_value = min(list(data.values()));\n",
    "        for i in data:\n",
    "            n[i] = (data[i]-min_value)/(max_value - min_value);\n",
    "            \n",
    "    return(n)\n",
    "\n",
    "class reading():\n",
    "    \n",
    "    def files_and_validation():\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Realiza a leitura dos arquivos contendo as matrizes de dados. Os dados inválidos das matrizes (-99) são\n",
    "            removidos, gerando vetores com apenas os valores válidos.\n",
    "            data ==> Vetor contendo apenas os valores válidos das matrizes\n",
    "            pos ==> Vetor contendo a posição que os valores válidos ocupam na matriz de dados original\n",
    "        \"\"\"\n",
    "        files_list = os.listdir('data-01-original');\n",
    "        files_list.sort();\n",
    "        data = [];\n",
    "        for i in range(len(files_list)):\n",
    "            m = np.genfromtxt('data-01-original/'+str(files_list[i]));\n",
    "            validated = [];\n",
    "            pos = [];\n",
    "            for row in range(len(m[:,0])):\n",
    "                for column in range(len(m[0,:])):\n",
    "                    if (m[row][column] != -99):\n",
    "                        validated.append(m[row,column]);\n",
    "                        pos.append([row,column]);\n",
    "            data.append(validated);\n",
    "                    \n",
    "        return(data,pos);\n",
    "\n",
    "    def timeSeriesGeneration(validated_data):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Arrays unidimensionais contendo os valores estimados das previsões\n",
    "        Returns:\n",
    "        --------\n",
    "            Série temporal associada a cada ponto válido (diferente de -99).\n",
    "            A série temporal 0 será composta por todos os valores na posição 0 dos 4464 arrays, e assim\n",
    "            em diante. O resultado são 587 séries temporais de tamanho 4464.\n",
    "        \"\"\"\n",
    "        time_series = {};\n",
    "        for i in range(len(validated_data[0])):\n",
    "            s = np.empty((0,0));\n",
    "            for j in range(len(validated_data)):\n",
    "                s = np.append(s,validated_data[j][i]);\n",
    "            time_series[i] = s;\n",
    "        \n",
    "        for t in range(len(time_series)):\n",
    "            for k in range(len(time_series[0])):\n",
    "                if (time_series[t][k] < 20):\n",
    "                    time_series[t][k] = 0;\n",
    "                \n",
    "        return(time_series);\n",
    "        \n",
    "class comparing():\n",
    "    \n",
    "    def __init__(self, graph_metrics):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Array de métricas que será usado como parâmetro para o restante das funções dessa classe.\n",
    "            São recebidos tanto os feature arrays, com métricas combinadas, quanto os sequence arrays, como é\n",
    "            o caso da sequência de graus.\n",
    "            As métricas enviadas são as pertencentes a todos os grafos. Sendo assim, self.metrics_array\n",
    "            receberá um array de tamanho 587, onde cada posição terá um array de métricas correspondente a\n",
    "            um grafo.\n",
    "            As funções de distância/similaridade irão computar a medida entre todos os pares (a,b) de métricas,\n",
    "            com a e b variando de 0 até 586, apenas desconsiderando casos como: \n",
    "                - a = b\n",
    "                - (b,a) se já existir um valor calculado para o par (a,b)\n",
    "        \"\"\"\n",
    "        self.metrics_array = graph_metrics\n",
    "    \n",
    "    def jensenshannon(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Jensen-Shannon, no formato de um dicionário, entre todos os \n",
    "            pares de grafos.\n",
    "            A função computa a raiz quadrada da divergência de Jensen-Shannon:\n",
    "                JSD(P||Q) = ((D(P||M) + D(Q||M))/2)^(1/2)\n",
    "                Onde:\n",
    "                    D é a divergência de Kullback-Leibler \n",
    "                    M = (P + Q)/2 \n",
    "        \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2205.\n",
    "                \n",
    "        \"\"\"\n",
    "        jensenshannon_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                jensenshannon_dist[i,j] = distance.jensenshannon(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(jensenshannon_dist)    \n",
    "    \n",
    "    \n",
    "    def euclidean(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância Euclidiana, no formato de um dicionário, entre todos os \n",
    "            pares de grafos.\n",
    "            Considerando os vetores, a e b, a distância euclidiana é calculada como:\n",
    "                e_dist(a,b) = ||a - b||\n",
    "        \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2204-2205.\n",
    "            \n",
    "        \"\"\"\n",
    "        euclidean_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                euclidean_dist[i,j] = distance.euclidean(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(euclidean_dist)\n",
    "\n",
    "    def manhattan(self):\n",
    "        \"\"\"    \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Manhattan (Cityblock), no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, a distância de manhattan é calculada como:\n",
    "                m_dist(a,b) = Σ(|ai - bi|)\n",
    "                i deve ser iterado a fim de percorrer todos os elementos de cada vetor.\n",
    "\n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2203.\n",
    "        \"\"\"\n",
    "        manhattan_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                manhattan_dist[i,j] = distance.cityblock(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(manhattan_dist)\n",
    "\n",
    "    def canberra(self):\n",
    "        \"\"\"   \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Canberra, no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, a distância de canberra é calculada como:\n",
    "                c_dist(a,b) = Σ((|ai - bi|)/(|ai|+|bi|))\n",
    "                i deve ser iterado a fim de percorrer todos os elementos de cada vetor\n",
    "\n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2202.\n",
    "        \"\"\"\n",
    "        canberra_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                canberra_dist[i,j] = distance.canberra(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(canberra_dist)\n",
    "\n",
    "    def cosine(self):\n",
    "        \"\"\"    \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância baseada em cosseno, no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, o cosseno entre esses dois vetores pode ser obtido pela\n",
    "            seguinte relação:\n",
    "                cos(θ) = (a·b)/(||a||*||b||)\n",
    "                cos_dist = 1 - cos(θ)\n",
    "\n",
    "                (a·b) é o produto escalar entre os dois vetores.\n",
    "                \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2204.\n",
    "        \"\"\"\n",
    "        cosine_sim = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                cosine_sim[i,j] = distance.cosine(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(cosine_sim)\n",
    "\n",
    "def mutual_information(ts):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        ts - Conjunto de séries temporais lidas inicialmente. Cada série é comparada com todas as outras usando \n",
    "        mutual information. \n",
    "    Returns:\n",
    "    --------\n",
    "        mi_dict - Retorna um dicionário. As chaves correspondem às séries e os valores são a distância geográfica e\n",
    "        a informação mútua\n",
    "    \"\"\"    \n",
    "    mi_dict = {};\n",
    "    ctrl = 1;\n",
    "    for i in range(len(ts)):\n",
    "        for j in range(ctrl,len(ts)):\n",
    "            mi = sk.normalized_mutual_info_score(ts[i], ts[j], average_method='arithmetic');\n",
    "            mi_dict[i,j] = [geo_dist[i,j],mi];\n",
    "        ctrl += 1;\n",
    "    return(mi_dict);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leitura das séries temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.33015155792236\n"
     ]
    }
   ],
   "source": [
    "# Estimated execution time: 24s\n",
    "init = time.time()\n",
    "\n",
    "# Time series\n",
    "validated_files,position = reading.files_and_validation() # removing -99 values and saving the position of the valid points in a dictionary\n",
    "meteorological_time_series = reading.timeSeriesGeneration(validated_files)\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-b9ccd43e42c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execution time: 300s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmutual_inf_all_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeteorological_time_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-161-6a6f93af13a0>\u001b[0m in \u001b[0;36mmutual_information\u001b[0;34m(ts)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_mutual_info_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'arithmetic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mmi_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgeo_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mctrl\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/cluster/_supervised.py\u001b[0m in \u001b[0;36mnormalized_mutual_info_score\u001b[0;34m(labels_true, labels_pred, average_method)\u001b[0m\n\u001b[1;32m   1006\u001b[0m             classes.shape[0] == clusters.shape[0] == 0):\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m     \u001b[0mcontingency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontingency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     contingency = contingency.astype(np.float64,\n\u001b[1;32m   1010\u001b[0m                                      **_astype_copy_false(contingency))\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/cluster/_supervised.py\u001b[0m in \u001b[0;36mcontingency_matrix\u001b[0;34m(labels_true, labels_pred, eps, sparse, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot set 'eps' when sparse=True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Execution time: 300s\n",
    "i = time.time();\n",
    "mutual_inf_all_edges = mutual_information(meteorological_time_series);\n",
    "e = time.time();\n",
    "print(e-i);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Thresholds\n",
    "    1. Limiar para produção de ~1270 arestas (mesmo número de arestas da rede GT-Pearson)\n",
    "    2. Limiar baseado no maior diâmetro \n",
    "    3. Limiar baseado nas maiores correlações (1%)\n",
    "\n",
    "#### Limiar para 1270 arestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_1270_edges = {}\n",
    "for i in mutual_inf_all_edges:\n",
    "    if mutual_inf_all_edges[i][1] >= 0.5833:\n",
    "        mi_1270_edges[i] = mutual_inf_all_edges[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Limiar baseado no maior diâmetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = igraph.Graph()\n",
    "full_graph.add_vertices(587)\n",
    "full_graph.add_edges(mutual_inf_all_edges)\n",
    "full_graph.es['weight'] = np.array(list(mutual_inf_all_edges.values()))[:,1]\n",
    "mi_threshold_diameter = {}\n",
    "thrshld_diameter = threshold.max_diameter_threshold(full_graph)\n",
    "for keys in mutual_inf_all_edges:\n",
    "    if mutual_inf_all_edges[keys][1] >= thrshld_diameter:\n",
    "        mi_threshold_diameter[keys] = mutual_inf_all_edges[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Limiar baseado nas maiores correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_all_edges_items = np.array(list(mutual_inf_all_edges.items()))\n",
    "mi_all_edges_items = mi_all_edges_items[mi_all_edges_items[:,1,1].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_inf_all_edges_sorted_values = {}\n",
    "mutual_inf_all_edges_sorted_keys = {}\n",
    "for i in range(len(mi_all_edges_items)):\n",
    "    mutual_inf_all_edges_sorted_keys[i] = [int(mi_all_edges_items[i,0,0]),int(mi_all_edges_items[i,0,1])]\n",
    "    mutual_inf_all_edges_sorted_values[i] = mi_all_edges_items[i,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(mutual_inf_all_edges_sorted_values)*0.01)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_inf_all_edges_sorted = {}\n",
    "for i in range((len(mutual_inf_all_edges_sorted_values)-1),(len(mutual_inf_all_edges_sorted_values) - int(len(mutual_inf_all_edges_sorted_values)*0.01+2)),-1):\n",
    "        mutual_inf_all_edges_sorted[mutual_inf_all_edges_sorted_keys[i][0],mutual_inf_all_edges_sorted_keys[i][1]] = mutual_inf_all_edges_sorted_values[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Geração das redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Backbone para cada rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
