{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sk\n",
    "import scipy \n",
    "import igraph\n",
    "import ts2vg # Time series to visibility graphs\n",
    "import scipy.spatial.distance as distance\n",
    "import scipy\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def threshold(adj,threshold):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        adj - Dicionário cuja chave é o índice dos pontos comparados e o valores é a resultante da medida de\n",
    "        distância/similaridade utilizada. \n",
    "        \n",
    "        threshold - limiar a ser aplicado.\n",
    "    Returns:\n",
    "    --------\n",
    "        Nova lista de adjacência com os valores abaixo do limiar definido.\n",
    "    \"\"\"\n",
    "    new_adj = {}\n",
    "    for i,j in adj:\n",
    "        if (adj[i,j] <= threshold):\n",
    "            new_adj[i,j] = adj[i,j]\n",
    "    return(new_adj)\n",
    "    \n",
    "def geographical_distance(adj,pos):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        adj - pares de pontos que correspondem a um ponto (série temporal) disposta no espaço geográfico da \n",
    "        bacia do rio Tamanduateí.\n",
    "        pos - índice (i,j) de cada ponto na matriz que representa o espaço geográfico.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        A distância euclidiana entre os pontos distribuídos na região analisada.\n",
    "    \"\"\"\n",
    "    geo_dist = {}\n",
    "    for i in adj:\n",
    "        a = pos[i[0]]\n",
    "        b = pos[i[1]]\n",
    "        dist = np.sqrt((a[0]-b[0])**2+(a[1]-b[1])**2)\n",
    "        geo_dist[i] = dist\n",
    "    return(geo_dist)\n",
    "\n",
    "def norm(data):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        Vetor numérico.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        Valores da vetor data entre o intervalo de 0 e 1.\n",
    "    \n",
    "    \"\"\"\n",
    "    n = []\n",
    "    max_value = max(data)\n",
    "    min_value = min(data)\n",
    "    for i in range(len(data)):\n",
    "        n.append((data[i]-min_value)/(max_value - min_value))\n",
    "    return(n)\n",
    "\n",
    "class reading():\n",
    "    \n",
    "    def files():\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Dados meteorológicos relacionados à região que compreende a bacia do rio Tamanduateí:\n",
    "            4464 arquivos em formato de matriz com 37 linhas e 36 colunas contendo a previsão de precipitação\n",
    "            para determinada região. Os valores -99 delimitam a região válida para as previsões.\n",
    "            Formato do nome: ppi-CZ-1-201501-1-0-0.txt\n",
    "                                      y   mo d h m\n",
    "            y: ano (2015)\n",
    "            mo: mês (1)\n",
    "            d: dia (1 - 31)\n",
    "            h: hora (0 - 23)  \n",
    "            m: minuto (00 - 50, a cada 10 minutos)\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        for day in range(0,31):\n",
    "            for hour in range(0,24):\n",
    "                for minutes in range(0,6):\n",
    "                    data[(day*144)+(hour*6)+(minutes)] = np.genfromtxt(\"01/ppi-CZ-1-201501-\"+str(day+1)+\"-\"+str(hour)+\"-\"+str(minutes*10)+\".txt\")\n",
    "\n",
    "        return(data)\n",
    "\n",
    "    def dataValidation(data):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Matrizes retornadas pela função reading.files()\n",
    "        Returns:\n",
    "        --------\n",
    "            Array unidimensional contendo os valores válidos (excluindo os valores -99)\n",
    "            e um array contendo a posição dos dados na matriz original.\n",
    "        \"\"\"\n",
    "        new_data = {}\n",
    "        new_idxs = {}\n",
    "        aux_data = np.empty((0,0))\n",
    "        idx = np.empty((0,2))\n",
    "        for keys in range(len(data)):\n",
    "            for rows in range(len(data[keys][:,0])):\n",
    "                for columns in range(len(data[keys][0,:])):\n",
    "                    if (data[keys][rows,columns] != -99):\n",
    "                        aux_data = np.append(aux_data,data[keys][rows,columns])\n",
    "                        idx = np.append(idx,[[rows,columns]],axis=0)\n",
    "            new_data[keys] = aux_data\n",
    "            new_idxs[keys] = idx\n",
    "            aux_data = np.empty((0,0))\n",
    "            idx = np.empty((0,2))\n",
    "        \n",
    "        return(new_data,new_idxs[0])\n",
    "\n",
    "    def timeSeriesGeneration(valid_data):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Arrays unidimensionais contendo os valores estimados das previsões\n",
    "        Returns:\n",
    "        --------\n",
    "            Série temporal associada a cada ponto válido (diferente de -99).\n",
    "            A série temporal 0 será composta por todos os valores na posição 0 dos 4464 arrays, e assim\n",
    "            em diante. O resultado são 587 séries temporais de tamanho 4464.\n",
    "        \"\"\"\n",
    "        time_series = {}\n",
    "        new_data = np.empty((0,0))\n",
    "        for time in range(len(valid_data[0])):\n",
    "            for data in range(len(valid_data)):\n",
    "                new_data = np.append(new_data,valid_data[data][time])\n",
    "            time_series[time] = new_data\n",
    "            new_data = np.empty((0,0))\n",
    "        \n",
    "        return(time_series)\n",
    "\n",
    "class network():\n",
    "    \n",
    "    def geo_graph(adj):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        \"\"\"\n",
    "        geo_graph = igraph.Graph()\n",
    "        geo_graph.add_vertices(587) # Número de séries temporais\n",
    "        for i in range(geo_graph.vcount()):\n",
    "            geo_graph.vs[i][\"label\"] = i # Enumerando os nós de 0 a 586\n",
    "        geo_graph.add_edges(adj)\n",
    "\n",
    "    def graphs(data):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Lista de valores inteiros que correspondem aos nós de uma rede. Os valores devem ser conectados\n",
    "            em sequência.\n",
    "            Exemplo:\n",
    "                data = (1,2,8,4,5,2,7,9,4)\n",
    "                adjacency_list from data: (1,2),(2,8),(8,4),(4,5),(5,2),(2,7),(7,9),(9,4)\n",
    "            Assim, um grafo seria construído usando o conjunto data como os nós da rede e o conjunto\n",
    "            adjacency_list seria responsável pela conexão dos nós.\n",
    "            Os pares repetidos na lista de adjacência irão contabilizar os pesos. Se um par de conexão se\n",
    "            repete 5 vezes, por exemplo, então o peso desse link é 5.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "            1. all_metrics - Dicionário contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            2. seq_metrics - Dicionário contendo 587 índices (587 grafos). Cada índice possui outro dicionário\n",
    "            com as sequências de valores de degree, betweenness e closeness.\n",
    "            3. global_metrics - Dicionário contendo as métricas assortativity degree, heterogeinity parameter,\n",
    "            density e diameter para todos os grafos.\n",
    "            4. local_metrics - Dicionário contendo as médias de betweenness, degree e closeness.\n",
    "        \"\"\"\n",
    "\n",
    "        # Graph creation from decimal integer array\n",
    "\n",
    "        graph = igraph.Graph()\n",
    "\n",
    "        #graph.add_vertices(max(data)+1)\n",
    "        graph.add_vertices(len(data))\n",
    "\n",
    "        #adjacency_list = np.empty((0,0), int)\n",
    "        aux_list = []\n",
    "        adjacency_list = []\n",
    "        weights = []\n",
    "        edge_weight = {}\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if not(len(data)-1 == i):\n",
    "                aux_list.append([data[i],data[i+1]])\n",
    "\n",
    "        # Counting repetitions\n",
    "        for i in range(len(aux_list)):\n",
    "            weights.append(aux_list.count(aux_list[i]))\n",
    "        \n",
    "        # keys: pair of edges\n",
    "        # value: weights\n",
    "        for i in range(len(aux_list)):\n",
    "            edge_weight[aux_list[i][0],aux_list[i][1]] = weights[i]\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            graph.vs[i][\"label\"] = i\n",
    "\n",
    "        graph.add_edges(list(edge_weight.keys())) # Full graph, with disconnected nodes\n",
    "        \n",
    "        graph.es['weight'] = list(edge_weight.values()) # Weight list based on how many times a pair of edges occurs\n",
    "\n",
    "        # Only nodes with degree > 0\n",
    "\n",
    "        disconnected = np.empty((0,0), int)\n",
    "        for i in range(graph.vcount()):\n",
    "            if (graph.vs[i].degree() == 0):\n",
    "                disconnected = np.append(disconnected, i)\n",
    "\n",
    "        graph.delete_vertices(disconnected)\n",
    "        \n",
    "        all_metrics, seq_metrics, global_metrics, local_metrics = network.metrics(graph)\n",
    "        \n",
    "        return(all_metrics, seq_metrics, global_metrics, local_metrics)\n",
    "        \n",
    "    def metrics(g):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Grafo criado na biblioteca igraph\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            1. feature_dict - Dicionário contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            2. seq_dict - Dicionário contendo 587 índices (587 grafos). Cada índice possui outro dicionário\n",
    "            com as sequências de valores de degree, betweenness e closeness.\n",
    "            3. feature_global_dict - Dicionário contendo as métricas assortativity degree, heterogeinity parameter,\n",
    "            density e diameter para todos os grafos.\n",
    "            4. feature_local_dict - Dicionário contendo as médias de betweenness, degree e closeness.           \n",
    "        \"\"\"\n",
    "\n",
    "        def heterogeinity(degree):\n",
    "            power_degree = [] # degree sequence \n",
    "            for i in degree:\n",
    "                power_degree.append(i**2)\n",
    "                hp = ( (sum(power_degree)/len(power_degree))/((sum(degree)/len(degree))**2) )\n",
    "            return(hp)\n",
    "\n",
    "        # Degree and Average Degree\n",
    "        degree_sequence = [round(i,4) for i in g.degree()]\n",
    "        avg_degree = round((sum(degree_sequence)/len(degree_sequence)),4)\n",
    "\n",
    "        # Diameter\n",
    "        diameter = round(g.diameter(),4)\n",
    "\n",
    "        # Betweenness and Average Betweenness\n",
    "        betweenness_sequence = [round(i,4) for i in g.betweenness()]\n",
    "        avg_betweenness = round((sum(betweenness_sequence)/len(betweenness_sequence)),4)\n",
    "\n",
    "        # Closeness and Average Closeness\n",
    "        closeness_sequence = [round(i,4) for i in g.closeness()]\n",
    "        avg_closeness = round(sum(closeness_sequence)/len(closeness_sequence),4)\n",
    "\n",
    "        # Density\n",
    "        density = round(g.density(),4)\n",
    "        \n",
    "        # Assortativity Degree\n",
    "        assor_degree = round(g.assortativity_degree(),4)\n",
    "        \n",
    "        # Heterogeinity parameter\n",
    "        hp = round(heterogeinity(g.degree()),4)\n",
    "\n",
    "        feature_dict = {\n",
    "            'Avg_Betweenness': avg_betweenness,\n",
    "            'Avg_Closeness': avg_closeness,\n",
    "            'Avg_Degree': avg_degree,\n",
    "            'Diameter': diameter,\n",
    "            'Density': density\n",
    "        }\n",
    "        \n",
    "        seq_dict = {\n",
    "            'Betweenness': betweenness_sequence,\n",
    "            'Closeness': closeness_sequence,\n",
    "            'Degree': degree_sequence,\n",
    "        }\n",
    "        \n",
    "        feature_global_dict = {\n",
    "            'Assortativity_Degree': assor_degree,\n",
    "            'Heterogeinity_Parameter': hp,\n",
    "            'Density': density,\n",
    "            'Diameter': diameter\n",
    "        }\n",
    "    \n",
    "        feature_local_dict = {\n",
    "            'Avg_Betweenness': avg_betweenness,\n",
    "            'Avg_Closeness': avg_closeness,\n",
    "            'Avg_Degree': avg_degree\n",
    "        }\n",
    "        \n",
    "        return(feature_dict,seq_dict,feature_global_dict,feature_local_dict)\n",
    "\n",
    "class algorithms():\n",
    "    \n",
    "    def DCSD(time_series,n): # Dynamical Characterization with Symbolic Dynamics - DCSD\n",
    "        '''\n",
    "        Parameters:\n",
    "        -----------\n",
    "            time_series - Série temporal a ser convertida em grafo.\n",
    "            n - tamanho da palavra binária usada na conversão binário/decimal\n",
    "            \n",
    "            Exemplo de aplicação do algoritmo:\n",
    "                1. Definir o valor máximo e mínimo de uma série temporal:\n",
    "                    1.1. x = [5,8,9,12,10,7,4,3,5,7,11]\n",
    "                    1.2. Max: 12\n",
    "                         Min: 3\n",
    "                2. Definir o centro da série temporal:\n",
    "                    2.1. centro: (12+3)/2 = 7.5\n",
    "                3. Gerar um array binário (b), tal como se segue:\n",
    "                    3.1. x(i) >= centro, então b(i) = 1\n",
    "                    3.2. x(i) < centro, então b(i) = 0\n",
    "                    3.3. b = [0,1,1,1,1,0,0,0,0,0,1]\n",
    "                4. Conversão da série binária em uma série decimal:\n",
    "                    4.1. A conversão será feita através de palavras binárias de tamanho N.\n",
    "                    4.2. O grupamento de tamanho 4 terá um comportamento deslizante, sempre com um passo\n",
    "                    à direita:\n",
    "                        4.2.1. Assumindo N = 4:\n",
    "                                [|0,1,1,1|,1,0,0,0,0,0,1]\n",
    "                                     7\n",
    "                                [0,|1,1,1,1|,0,0,0,0,0,1]\n",
    "                                       15\n",
    "                                [0,1,|1,1,1,0|,0,0,0,0,1]\n",
    "                                         14\n",
    "                                [0,1,1,|1,1,0,0|,0,0,0,1]\n",
    "                                          12\n",
    "                                [0,1,1,1,|1,0,0,0|,0,0,1]\n",
    "                                             8\n",
    "                                [0,1,1,1,1,|0,0,0,0|,0,1]\n",
    "                                               0\n",
    "                                [0,1,1,1,1,0,|0,0,0,0|,1]\n",
    "                                                 0\n",
    "                                [0,1,1,1,1,0,0,|0,0,0,1|]\n",
    "                                                   1\n",
    "\n",
    "                                Nova série decimal inteira = [7,15,14,12,8,0,0,1]\n",
    "\n",
    "                5. Cada valor da nova série gerada corresponde a um nó e a conexão entre esses nós se dá\n",
    "                através da sequência dos valores, como se segue: (7,15), (15,14), (14,12), e assim por diante.\n",
    "            \n",
    "            Returns:\n",
    "            --------\n",
    "                graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "                average closeness, density e diameter.\n",
    "                graph_degree - Array contendo o degree de cada nó da rede.\n",
    "                graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "                graph_closeness - Array contendo o closeness de cada nó da rede.\n",
    "\n",
    "            References:\n",
    "            -----------\n",
    "                FREITAS, Vander LS; LACERDA, Juliana C.; MACAU, Elbert EN.\n",
    "                Complex Networks Approach for Dynamical Characterization of Nonlinear Systems.\n",
    "                International Journal of Bifurcation and Chaos, v. 29, n. 13, p. 1950188, 2019.\n",
    "            '''\n",
    "        center = (max(time_series)+min(time_series))/2\n",
    "\n",
    "        # Converting time_series to binary\n",
    "\n",
    "        binary_array = np.empty((0,0), int)\n",
    "\n",
    "        for i in time_series:\n",
    "            if i >= center:\n",
    "                binary_array = np.append(binary_array,1)\n",
    "            else:\n",
    "                binary_array = np.append(binary_array,0)\n",
    "\n",
    "        # Converting the binary array to decimal (integer)\n",
    "\n",
    "        decimal_array = np.empty((0,0), int)\n",
    "\n",
    "        for i in range(len(binary_array)-n+1): \n",
    "            word = binary_array[i:i+n]\n",
    "            string_word = ''\n",
    "            for j in range(len(word)): \n",
    "                string_word = string_word + str(word[j])\n",
    "            # Converting to decimal\n",
    "            decimal_number = int(string_word,2)\n",
    "            decimal_array = np.append(decimal_array,decimal_number)     \n",
    "\n",
    "        all_metrics_DCSD, seq_metrics_DCSD, global_metrics_DCSD, local_metrics_DCSD = network.graphs(decimal_array)\n",
    "\n",
    "        return(all_metrics_DCSD, seq_metrics_DCSD, global_metrics_DCSD, local_metrics_DCSD)\n",
    "\n",
    "    def DCTIF(time_series, n): # Dynamical Characterization using the Top Integral Function - DCTIF\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            time_series - Série temporal a ser convertida em grafo.\n",
    "            n - Tamanho do intervalo em que os dados serão mapeados.            \n",
    "            Exemplo:\n",
    "                1. A função DCTIF é definida como: Yk = [N · xk ] = min{i ∈ Z | N · xk ≤ i}\n",
    "                    1.1. Exemplo: x = [0.467, 1.0, 0.933, 0.8, 0.533, 0.0, 0.0, 0.067, 0.0]\n",
    "                    1.2. Usando N = 5\n",
    "                    1.3. Yk[0] = min{i ∈ Z | 5 · 0.467 ≤ i} = min{i ∈ Z | 2.335 ≤ i} = 3\n",
    "                    1.4. Yk = [3,5,5,4,3,1,1,1,1]\n",
    "                    1.5. Cada valor da nova série gerada corresponde a um nó e a conexão entre eles se dá\n",
    "                    através da sequência dos valores, como se segue: (3,5), (5,5), (5,4), e assim em diante.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            graph_degree - Array contendo o degree de cada nó da rede.\n",
    "            graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "            graph_closeness - Array contendo o closeness de cada nó da rede. \n",
    "            \n",
    "        References:\n",
    "        -----------\n",
    "            FREITAS, Vander LS; LACERDA, Juliana C.; MACAU, Elbert EN.\n",
    "            Complex Networks Approach for Dynamical Characterization of Nonlinear Systems.\n",
    "            International Journal of Bifurcation and Chaos, v. 29, n. 13, p. 1950188, 2019.\n",
    "        \"\"\"\n",
    "        # Normalizing the data\n",
    "        time_series_normalized = np.empty((0,0), float)\n",
    "        min_value = min(time_series)\n",
    "        max_value = max(time_series)\n",
    "        for i in time_series:\n",
    "            time_series_normalized = np.append(time_series_normalized, ((i-min_value)/(max_value-min_value)))    \n",
    "\n",
    "        nodes_array = np.empty((0,0),int)\n",
    "        for i in time_series_normalized:\n",
    "            if (i*n == 0):\n",
    "                nodes_array = np.append(nodes_array,int(1))\n",
    "            elif (round(i*n) - i*n >= 0.0):\n",
    "                nodes_array = np.append(nodes_array,int(round(i*n)))\n",
    "            else:\n",
    "                nodes_array = np.append(nodes_array,int(round(i*n) + 1.0))\n",
    "\n",
    "        all_metrics_DCTIF, seq_metrics_DCTIF, global_metrics_DCTIF, local_metrics_DCTIF = network.graphs(nodes_array)\n",
    "\n",
    "        return(all_metrics_DCTIF, seq_metrics_DCTIF, global_metrics_DCTIF, local_metrics_DCTIF)\n",
    "\n",
    "    def VG(time_series):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Uma série temporal que será transformada em um grafo do tipo natural visibility graph. Cada ponto\n",
    "            da série será convertido em um nó, sendo que a conexão entre os nós é definida de acordo com um \n",
    "            critério de visibilidade.\n",
    "            Exemplo:\n",
    "                Critério de visibilidade: yc < yb + (ya - yb)*((tb - tc)/(tb - ta))\n",
    "                    Dois pontos quaisquer em uma série temporal, (ya,ta) e (yb,tb), serão conectados no grafo,\n",
    "                    se, e somente se, um terceiro ponto, (yc,tc), colocado entre eles for capaz de satisfazer\n",
    "                    o critério de visibilidade.\n",
    "                y = [5,8,9,12,10,7,4,3,5,7,11]\n",
    "                t = [0,1,2,3,4,5,6,7,8,9,10] -> eixo temporal \n",
    "                Avaliando os pontos ya = 5 e yb = 8:\n",
    "                - Não há pontos intermediários, yc = 0\n",
    "                - Critério:\n",
    "                    0 < 8 + (5-8)*((1-0)/(1-0))\n",
    "                    0 < 8 + (-3)*1 \n",
    "                    0 < 5\n",
    "                    Logo, os pontos 5 e 8 serão conectados.\n",
    "                Avaliando os pontos ya = 9 e yb = 10:\n",
    "                - Ponto intermediário: yc = 12\n",
    "                - Critério:\n",
    "                    12 < 10 + (9 - 10)*((4-3)/(4-2))\n",
    "                    12 < 10 + (-1)*(1/2)\n",
    "                    12 < 10 - 1/2\n",
    "                    12 < 9.5\n",
    "                    Condição não satisfeita. Sendo assim, os pontos 9 e 10 não seriam conectados na rede.\n",
    "                \n",
    "        Returns:\n",
    "        --------\n",
    "            graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            graph_degree - Array contendo o degree de cada nó da rede.\n",
    "            graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "            graph_closeness - Array contendo o closeness de cada nó da rede.\n",
    "\n",
    "        References:\n",
    "        -----------\n",
    "            LACASA, Lucas et al. \n",
    "            From time series to complex networks: The visibility graph.\n",
    "            Proceedings of the National Academy of Sciences, v. 105, n. 13, p. 4972-4975, 2008.\n",
    "        \"\"\"\n",
    "        vg_igraph = ts2vg.NaturalVisibilityGraph(time_series).as_igraph()\n",
    "        \n",
    "        all_metrics_VG, seq_metrics_VG, global_metrics_VG, local_metrics_VG = network.metrics(vg_igraph)\n",
    "        \n",
    "        return(all_metrics_VG, seq_metrics_VG, global_metrics_VG, local_metrics_VG)\n",
    "\n",
    "class saving():\n",
    "    \n",
    "    def saving_metrics(all_metrics_DCSD,all_metrics_DCTIF,all_metrics_VG):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Recebe dicionários contendo métricas de todos os grafos para cada algoritmo. Cada dicionário contém \n",
    "            chaves que vão de 0 até 586, representando os 587 grafos. Os valores de cada chaves são dicionários\n",
    "            contendo as métricas average degree, average betweenness, average closeness, density e diameter.\n",
    "            Os dicionários são convertidos em DataFrames Pandas e depois são salvos no formato .csv.\n",
    "        \"\"\"\n",
    "        dcsd_df = pd.DataFrame(data=all_metrics_DCSD)\n",
    "        dctif_df = pd.DataFrame(data=all_metrics_DCTIF)\n",
    "        vg_df = pd.DataFrame(data=all_metrics_VG)\n",
    "\n",
    "        dcsd_df.T.to_csv('DCSD/DCSD-metrics.csv',index=False)\n",
    "        dctif_df.T.to_csv('DCTIF/DCTIF-metrics.csv',index=False)\n",
    "        vg_df.T.to_csv('VG/VG-metrics.csv',index=False)\n",
    "   \n",
    "    \n",
    "    def saving_sequences(seq_metrics_DCSD,seq_metrics_DCTIF,seq_metrics_VG):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Recebe dicioinários com as sequências de métricas para todos os grafos.\n",
    "            Cada índice do dicionário (corresponde a um grafo) possui um outro dicionário contendo as\n",
    "            sequências de degree, betweenness e closeness para aquele grafo. \n",
    "            Essas métricas serão separadas e cada uma será salva em um arquivo .csv contendo a sequência de \n",
    "            dada métrica para os 587 grafos.\n",
    "        \"\"\"\n",
    "        \n",
    "        def check_length(data):\n",
    "            \"\"\"\n",
    "            Parameters:\n",
    "            -----------\n",
    "                Sequência de valores correspondentes a uma dada métrica.\n",
    "                Os grafos gerados pelos algoritmos DCSD e DCTIF possuem tamanhos diferentes, o que gera \n",
    "                sequências de tamanhos diferentes. A função irá padronizar esse comprimento adicionando 0 ao \n",
    "                final das sequências.\n",
    "            Returns:\n",
    "            --------\n",
    "                Uma sequência de métricas com tamanho padrão de 4464. No caso das métricas geradas pelo \n",
    "                visibility graph, nada será feito.\n",
    "            \"\"\"\n",
    "            if (len(data) != 4464):\n",
    "                for i in range(4464-len(data)):\n",
    "                    data.append(0)\n",
    "            return(data)\n",
    "\n",
    "        btw_DCSD = {}\n",
    "        clo_DCSD = {}\n",
    "        deg_DCSD = {}\n",
    "        btw_DCTIF = {}\n",
    "        clo_DCTIF = {}\n",
    "        deg_DCTIF = {}\n",
    "        btw_VG = {}\n",
    "        clo_VG = {}\n",
    "        deg_VG = {}\n",
    "        for i in range(len(seq_metrics_DCSD)):\n",
    "            btw_DCSD[i] = check_length(seq_metrics_DCSD[i]['Betweenness'])\n",
    "            clo_DCSD[i] = check_length(seq_metrics_DCSD[i]['Closeness'])\n",
    "            deg_DCSD[i] = check_length(seq_metrics_DCSD[i]['Degree'])\n",
    "            btw_DCTIF[i] = check_length(seq_metrics_DCTIF[i]['Betweenness'])\n",
    "            clo_DCTIF[i] = check_length(seq_metrics_DCTIF[i]['Closeness'])\n",
    "            deg_DCTIF[i] = check_length(seq_metrics_DCTIF[i]['Degree'])\n",
    "            btw_VG[i] = check_length(seq_metrics_VG[i]['Betweenness'])\n",
    "            clo_VG[i] = check_length(seq_metrics_VG[i]['Closeness'])\n",
    "            deg_VG[i] = check_length(seq_metrics_VG[i]['Degree'])\n",
    "\n",
    "        #DCSD\n",
    "        btw_DCSD_df = pd.DataFrame(data=btw_DCSD)\n",
    "        clo_DCSD_df = pd.DataFrame(data=clo_DCSD)\n",
    "        deg_DCSD_df = pd.DataFrame(data=deg_DCSD)\n",
    "\n",
    "        btw_DCSD_df.to_csv('DCSD/DCSD-betweenness.csv',index=False)\n",
    "        clo_DCSD_df.to_csv('DCSD/DCSD-closeness.csv',index=False)\n",
    "        deg_DCSD_df.to_csv('DCSD/DCSD-degree.csv',index=False)\n",
    "\n",
    "        #DCTIF\n",
    "        btw_DCTIF_df = pd.DataFrame(data=btw_DCTIF)\n",
    "        clo_DCTIF_df = pd.DataFrame(data=clo_DCTIF)\n",
    "        deg_DCTIF_df = pd.DataFrame(data=deg_DCTIF)\n",
    "\n",
    "        btw_DCTIF_df.to_csv('DCTIF/DCTIF-betweenness.csv',index=False)\n",
    "        clo_DCTIF_df.to_csv('DCTIF/DCTIF-closeness.csv',index=False)\n",
    "        deg_DCTIF_df.to_csv('DCTIF/DCTIF-degree.csv',index=False)    \n",
    "\n",
    "        #VG\n",
    "        btw_VG_df = pd.DataFrame(data=btw_VG)\n",
    "        clo_VG_df = pd.DataFrame(data=clo_VG)\n",
    "        deg_VG_df = pd.DataFrame(data=deg_VG)\n",
    "\n",
    "        btw_VG_df.to_csv('VG/VG-betweenness.csv',index=False)\n",
    "        clo_VG_df.to_csv('VG/VG-closeness.csv',index=False)\n",
    "        deg_VG_df.to_csv('VG/VG-degree.csv',index=False) \n",
    "    \n",
    "    def saving_global_metrics(global_metrics_DCSD,global_metrics_DCTIF,global_metrics_VG):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Recebe os dicionários de métricas globais e os salva no formato .csv.\n",
    "        \"\"\"\n",
    "        global_metrics_DCSD_df = pd.DataFrame(data=global_metrics_DCSD)\n",
    "        global_metrics_DCTIF_df = pd.DataFrame(data=global_metrics_DCTIF)\n",
    "        global_metrics_VG_df = pd.DataFrame(data=global_metrics_VG)\n",
    "\n",
    "        global_metrics_DCSD_df.T.to_csv('DCSD/DCSD-global-metrics.csv',index=False)\n",
    "        global_metrics_DCTIF_df.T.to_csv('DCTIF/DCTIF-global-metrics.csv',index=False)\n",
    "        global_metrics_VG_df.T.to_csv('VG/VG-global-metrics.csv',index=False)\n",
    "\n",
    "    def saving_local_metrics(local_metrics_DCSD,local_metrics_DCTIF,local_metrics_VG):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Recebe os dicionários de métricas locais e os salva no formato .csv.\n",
    "        \"\"\"\n",
    "        local_metrics_DCSD_df = pd.DataFrame(data=local_metrics_DCSD)\n",
    "        local_metrics_DCTIF_df = pd.DataFrame(data=local_metrics_DCTIF)\n",
    "        local_metrics_VG_df = pd.DataFrame(data=local_metrics_VG)\n",
    "\n",
    "        local_metrics_DCSD_df.T.to_csv('DCSD/DCSD-local-metrics.csv',index=False)\n",
    "        local_metrics_DCTIF_df.T.to_csv('DCTIF/DCTIF-local-metrics.csv',index=False)\n",
    "        local_metrics_VG_df.T.to_csv('VG/VG-local-metrics.csv',index=False)\n",
    "    \n",
    "        \n",
    "class comparing():\n",
    "    \n",
    "    def __init__(self, graph_metrics):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Array de métricas que será usado como parâmetro para o restante das funções dessa classe.\n",
    "            São recebidos tanto os feature arrays, com métricas combinadas, quanto os sequence arrays, como é\n",
    "            o caso da sequência de graus.\n",
    "            As métricas enviadas são as pertencentes a todos os grafos. Sendo assim, self.metrics_array\n",
    "            receberá um array de tamanho 587, onde cada posição terá um array de métricas correspondente a\n",
    "            um grafo.\n",
    "            As funções de distância/similaridade irão computar a medida entre todos os pares (a,b) de métricas,\n",
    "            com a e b variando de 0 até 586, apenas desconsiderando casos como: \n",
    "                - a = b\n",
    "                - (b,a) se já existir um valor calculado para o par (a,b)\n",
    "        \"\"\"\n",
    "        self.metrics_array = graph_metrics\n",
    "    \n",
    "    def jensenshannon(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Jensen-Shannon, no formato de um dicionário, entre todos os \n",
    "            pares de grafos.\n",
    "            A função computa a raiz quadrada da divergência de Jensen-Shannon:\n",
    "                JSD(P||Q) = ((D(P||M) + D(Q||M))/2)^(1/2)\n",
    "                Onde:\n",
    "                    D é a divergência de Kullback-Leibler \n",
    "                    M = (P + Q)/2 \n",
    "        \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2205.\n",
    "                \n",
    "        \"\"\"\n",
    "        jensenshannon_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                jensenshannon_dist[i,j] = distance.jensenshannon(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(jensenshannon_dist)    \n",
    "    \n",
    "    \n",
    "    def euclidean(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância Euclidiana, no formato de um dicionário, entre todos os \n",
    "            pares de grafos.\n",
    "            Considerando os vetores, a e b, a distância euclidiana é calculada como:\n",
    "                e_dist(a,b) = ||a - b||\n",
    "        \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2204-2205.\n",
    "            \n",
    "        \"\"\"\n",
    "        euclidean_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                euclidean_dist[i,j] = distance.euclidean(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(euclidean_dist)\n",
    "\n",
    "    def manhattan(self):\n",
    "        \"\"\"    \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Manhattan (Cityblock), no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, a distância de manhattan é calculada como:\n",
    "                m_dist(a,b) = Σ(|ai - bi|)\n",
    "                i deve ser iterado a fim de percorrer todos os elementos de cada vetor.\n",
    "\n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2203.\n",
    "        \"\"\"\n",
    "        manhattan_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                manhattan_dist[i,j] = distance.cityblock(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(manhattan_dist)\n",
    "\n",
    "    def canberra(self):\n",
    "        \"\"\"   \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Canberra, no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, a distância de canberra é calculada como:\n",
    "                c_dist(a,b) = Σ((|ai - bi|)/(|ai|+|bi|))\n",
    "                i deve ser iterado a fim de percorrer todos os elementos de cada vetor\n",
    "\n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2202.\n",
    "        \"\"\"\n",
    "        canberra_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                canberra_dist[i,j] = distance.canberra(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(canberra_dist)\n",
    "\n",
    "    def cosine(self):\n",
    "        \"\"\"    \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância baseada em cosseno, no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, o cosseno entre esses dois vetores pode ser obtido pela\n",
    "            seguinte relação:\n",
    "                cos(θ) = (a·b)/(||a||*||b||)\n",
    "                cos_dist = 1 - cos(θ)\n",
    "\n",
    "                (a·b) é o produto escalar entre os dois vetores.\n",
    "                \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2204.\n",
    "        \"\"\"\n",
    "        cosine_sim = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                cosine_sim[i,j] = distance.cosine(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(cosine_sim)\n",
    "# -------------------------------------------------------------------------------------------------------------    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading files and time series generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated execution time: 59,17s\n",
    "init = time.time()\n",
    "\n",
    "# Time series\n",
    "files = reading.files()\n",
    "validated_files,position = reading.dataValidation(files) # removing -99 values\n",
    "meteorological_time_series = reading.timeSeriesGeneration(validated_files)\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estimated execution time: 1783s\n",
    "init = time.time()\n",
    "\n",
    "all_metrics_VG = {}\n",
    "seq_metrics_VG = {}\n",
    "global_metrics_VG = {}\n",
    "local_metrics_VG = {}\n",
    "\n",
    "all_metrics_DCSD = {}\n",
    "seq_metrics_DCSD = {}\n",
    "global_metrics_DCSD = {}\n",
    "local_metrics_DCSD = {}\n",
    "\n",
    "all_metrics_DCTIF = {}\n",
    "seq_metrics_DCTIF = {}\n",
    "global_metrics_DCTIF = {}\n",
    "local_metrics_DCTIF = {}\n",
    "\n",
    "for idx in range(len(meteorological_time_series)):\n",
    "    print(idx,\"de\",(len(meteorological_time_series)-1))\n",
    "    all_metrics_VG[idx], seq_metrics_VG[idx], global_metrics_VG[idx], local_metrics_VG[idx] = algorithms.VG(meteorological_time_series[idx])\n",
    "    all_metrics_DCSD[idx], seq_metrics_DCSD[idx], global_metrics_DCSD[idx], local_metrics_DCSD[idx] = algorithms.DCSD(meteorological_time_series[idx],10)\n",
    "    all_metrics_DCTIF[idx], seq_metrics_DCTIF[idx], global_metrics_DCTIF[idx], local_metrics_DCTIF[idx] = algorithms.DCTIF(meteorological_time_series[idx],50)\n",
    "    \n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated excecution time: 13s\n",
    "init = time.time()\n",
    "\n",
    "saving.saving_metrics(all_metrics_DCSD,all_metrics_DCTIF,all_metrics_VG)\n",
    "saving.saving_sequences(seq_metrics_DCSD,seq_metrics_DCTIF,seq_metrics_VG)\n",
    "saving.saving_global_metrics(global_metrics_DCSD,global_metrics_DCTIF,global_metrics_VG)\n",
    "saving.saving_local_metrics(local_metrics_DCSD,local_metrics_DCTIF,local_metrics_VG)\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando as distâncias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility Graphs - VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VG\n",
    "# Tempo de execução: 239.57s\n",
    "init = time.time()\n",
    "\n",
    "vg_metrics_df = pd.read_csv(\"VG-metrics.csv\") # Cada linha do DataFrame é um vetor de características\n",
    "vg_degrees_df = pd.read_csv(\"VG-degrees.csv\") # Cada coluna representa a distribuição de graus de uma rede\n",
    "vg_betweenness_df = pd.read_csv(\"VG-betweenness.csv\") # Cada coluna representa a distribuição de betweenness de uma rede\n",
    "vg_closeness_df = pd.read_csv(\"VG-closeness.csv\") # Cada coluna representa a distribuição de closeness de uma rede\n",
    "\n",
    "vg_metrics_array = vg_metrics_df.to_numpy() # Cada posição do array possui um vetor de características\n",
    "vg_degrees_array = vg_degrees_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de graus\n",
    "vg_betweenness_array = vg_betweenness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de betweenness\n",
    "vg_closeness_array = vg_closeness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de closeness\n",
    "\n",
    "# Calculando as métricas entre todos os vetores de características.\n",
    "\n",
    "dist_vg_metrics = comparing(vg_metrics_array)\n",
    "\n",
    "\n",
    "euclidean_dist_vg_metrics = dist_vg_metrics.euclidean() # Não é capaz de captar correlação\n",
    "manhattan_dist_vg_metrics = dist_vg_metrics.manhattan() # Não é capaz de captar correlação\n",
    "canberra_dist_vg_metrics = dist_vg_metrics.canberra() # Não é capaz de captar correlação\n",
    "cosine_dist_vg_metrics = dist_vg_metrics.cosine() # Não é capaz de captar correlação\n",
    "jensenshannon_dist_vg_metrics = dist_vg_metrics.jensenshannon() # Não é capaz de captar correlação \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com distribuição de graus.\n",
    "\n",
    "dist_vg_degrees = comparing(vg_degrees_array)\n",
    "\n",
    "euclidean_dist_vg_degrees = dist_vg_degrees.euclidean() # Há correlação, mas a definição do limiar é problemática\n",
    "manhattan_dist_vg_degrees = dist_vg_degrees.manhattan() # Limiar consistente. Teste em: <18000\n",
    "canberra_dist_vg_degrees = dist_vg_degrees.canberra() # Limiar pouco consistente. Teste em: <330\n",
    "cosine_dist_vg_degrees = dist_vg_degrees.cosine() # Limiar consistente. Teste em: <0.27\n",
    "jensenshannon_dist_vg_degrees = dist_vg_degrees.jensenshannon() # Limiar consistente. Teste em: <0.27\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de betweenness.\n",
    "\n",
    "dist_vg_betweenness = comparing(vg_betweenness_array)\n",
    "\n",
    "euclidean_dist_vg_betweenness = dist_vg_betweenness.euclidean() #\n",
    "manhattan_dist_vg_betweenness = dist_vg_betweenness.manhattan() # \n",
    "canberra_dist_vg_betweenness = dist_vg_betweenness.canberra() # \n",
    "cosine_dist_vg_betweenness = dist_vg_betweenness.cosine() # \n",
    "jensenshannon_dist_vg_betweenness = dist_vg_betweenness.jensenshannon() #\n",
    "\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de closeness.\n",
    "\n",
    "dist_vg_closeness = comparing(vg_closeness_array)\n",
    "\n",
    "euclidean_dist_vg_closeness = dist_vg_closeness.euclidean() # \n",
    "manhattan_dist_vg_closeness = dist_vg_closeness.manhattan() #\n",
    "canberra_dist_vg_closeness = dist_vg_closeness.canberra() #\n",
    "cosine_dist_vg_closeness = dist_vg_closeness.cosine() # \n",
    "jensenshannon_dist_vg_closeness = dist_vg_closeness.jensenshannon() # \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamical Characterization using Symbolic Dynamics - DCSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCSD\n",
    "# Tempo de execução: 177s\n",
    "init = time.time()\n",
    "\n",
    "dcsd_metrics_df = pd.read_csv(\"DCSD-metrics.csv\") # Cada linha do DataFrame é um vetor de características\n",
    "dcsd_degrees_df = pd.read_csv(\"DCSD-degrees.csv\") # Cada coluna representa a distribuição de graus de uma rede\n",
    "dcsd_betweenness_df = pd.read_csv(\"DCSD-betweenness.csv\") # Cada coluna representa a distribuição de betweenness de uma rede\n",
    "dcsd_closeness_df = pd.read_csv(\"DCSD-closeness.csv\") # Cada coluna representa a distribuição de closeness de uma rede\n",
    "\n",
    "dcsd_metrics_array = dcsd_metrics_df.to_numpy() # Cada posição do array possui um vetor de características\n",
    "dcsd_degrees_array = dcsd_degrees_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de graus\n",
    "dcsd_betweenness_array = dcsd_betweenness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de betweenness\n",
    "dcsd_closeness_array = dcsd_closeness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de closeness\n",
    "\n",
    "# Calculando as métricas entre todos os vetores de características.\n",
    "\n",
    "dist_dcsd_metrics = comparing(dcsd_metrics_array)\n",
    "\n",
    "\n",
    "euclidean_dist_dcsd_metrics = dist_dcsd_metrics.euclidean() # \n",
    "manhattan_dist_dcsd_metrics = dist_dcsd_metrics.manhattan() # \n",
    "canberra_dist_dcsd_metrics = dist_dcsd_metrics.canberra() # \n",
    "cosine_dist_dcsd_metrics = dist_dcsd_metrics.cosine() # \n",
    "jensenshannon_dist_dcsd_metrics = dist_dcsd_metrics.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com distribuição de graus.\n",
    "\n",
    "dist_dcsd_degrees = comparing(dcsd_degrees_array)\n",
    "\n",
    "euclidean_dist_dcsd_degrees = dist_dcsd_degrees.euclidean() # \n",
    "manhattan_dist_dcsd_degrees = dist_dcsd_degrees.manhattan() # \n",
    "canberra_dist_dcsd_degrees = dist_dcsd_degrees.canberra() # \n",
    "cosine_dist_dcsd_degrees = dist_dcsd_degrees.cosine() # \n",
    "jensenshannon_dist_dcsd_degrees = dist_dcsd_degrees.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de betweenness.\n",
    "\n",
    "dist_dcsd_betweenness = comparing(dcsd_betweenness_array)\n",
    "\n",
    "euclidean_dist_dcsd_betweenness = dist_dcsd_betweenness.euclidean() #\n",
    "manhattan_dist_dcsd_betweenness = dist_dcsd_betweenness.manhattan() # \n",
    "canberra_dist_dcsd_betweenness = dist_dcsd_betweenness.canberra() # \n",
    "cosine_dist_dcsd_betweenness = dist_dcsd_betweenness.cosine() # \n",
    "jensenshannon_dist_dcsd_betweenness = dist_dcsd_betweenness.jensenshannon() #\n",
    "\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de closeness.\n",
    "\n",
    "dist_dcsd_closeness = comparing(dcsd_closeness_array)\n",
    "\n",
    "euclidean_dist_dcsd_closeness = dist_dcsd_closeness.euclidean() # \n",
    "manhattan_dist_dcsd_closeness = dist_dcsd_closeness.manhattan() #\n",
    "canberra_dist_dcsd_closeness = dist_dcsd_closeness.canberra() #\n",
    "cosine_dist_dcsd_closeness = dist_dcsd_closeness.cosine() # \n",
    "jensenshannon_dist_dcsd_closeness = dist_dcsd_closeness.jensenshannon() # \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamical Characterization using the Top Integral Function - DCTIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCTIF\n",
    "# Tempo de execução: 159s\n",
    "init = time.time()\n",
    "\n",
    "dctif_metrics_df = pd.read_csv(\"DCTIF-metrics.csv\") # Cada linha do DataFrame é um vetor de características\n",
    "dctif_degrees_df = pd.read_csv(\"DCTIF-degrees.csv\") # Cada coluna representa a distribuição de graus de uma rede\n",
    "dctif_betweenness_df = pd.read_csv(\"DCTIF-betweenness.csv\") # Cada coluna representa a distribuição de betweenness de uma rede\n",
    "dctif_closeness_df = pd.read_csv(\"DCTIF-closeness.csv\") # Cada coluna representa a distribuição de closeness de uma rede\n",
    "\n",
    "dctif_metrics_array = dctif_metrics_df.to_numpy() # Cada posição do array possui um vetor de características\n",
    "dctif_degrees_array = dctif_degrees_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de graus\n",
    "dctif_betweenness_array = dctif_betweenness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de betweenness\n",
    "dctif_closeness_array = dctif_closeness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de closeness\n",
    "\n",
    "# Calculando as métricas entre todos os vetores de características.\n",
    "\n",
    "dist_dctif_metrics = comparing(dctif_metrics_array)\n",
    "\n",
    "\n",
    "euclidean_dist_dctif_metrics = dist_dctif_metrics.euclidean() # \n",
    "manhattan_dist_dctif_metrics = dist_dctif_metrics.manhattan() # \n",
    "canberra_dist_dctif_metrics = dist_dctif_metrics.canberra() # \n",
    "cosine_dist_dctif_metrics = dist_dctif_metrics.cosine() # \n",
    "jensenshannon_dist_dctif_metrics = dist_dctif_metrics.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com distribuição de graus.\n",
    "\n",
    "dist_dctif_degrees = comparing(dctif_degrees_array)\n",
    "\n",
    "euclidean_dist_dctif_degrees = dist_dctif_degrees.euclidean() # \n",
    "manhattan_dist_dctif_degrees = dist_dctif_degrees.manhattan() # \n",
    "canberra_dist_dctif_degrees = dist_dctif_degrees.canberra() # \n",
    "cosine_dist_dctif_degrees = dist_dctif_degrees.cosine() # \n",
    "jensenshannon_dist_dctif_degrees = dist_dctif_degrees.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de betweenness.\n",
    "\n",
    "dist_dctif_betweenness = comparing(dctif_betweenness_array)\n",
    "\n",
    "euclidean_dist_dctif_betweenness = dist_dctif_betweenness.euclidean() #\n",
    "manhattan_dist_dctif_betweenness = dist_dctif_betweenness.manhattan() # \n",
    "canberra_dist_dctif_betweenness = dist_dctif_betweenness.canberra() # \n",
    "cosine_dist_dctif_betweenness = dist_dctif_betweenness.cosine() # \n",
    "jensenshannon_dist_dctif_betweenness = dist_dctif_betweenness.jensenshannon() #\n",
    "\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de closeness.\n",
    "\n",
    "dist_dctif_closeness = comparing(dctif_closeness_array)\n",
    "\n",
    "euclidean_dist_dctif_closeness = dist_dctif_closeness.euclidean() # \n",
    "manhattan_dist_dctif_closeness = dist_dctif_closeness.manhattan() #\n",
    "canberra_dist_dctif_closeness = dist_dctif_closeness.canberra() #\n",
    "cosine_dist_dctif_closeness = dist_dctif_closeness.cosine() # \n",
    "jensenshannon_dist_dctif_closeness = dist_dctif_closeness.jensenshannon() # \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
