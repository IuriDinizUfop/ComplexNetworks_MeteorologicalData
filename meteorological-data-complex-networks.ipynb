{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sk\n",
    "import scipy \n",
    "import igraph\n",
    "import ts2vg # Time series to visibility graphs\n",
    "import scipy.spatial.distance as distance\n",
    "import scipy\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def threshold(adj,threshold):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        adj - Dicionário cuja chave é o índice dos pontos comparados e o valores é a resultante da medida de\n",
    "        distância/similaridade utilizada. \n",
    "        \n",
    "        threshold - limiar a ser aplicado.\n",
    "    Returns:\n",
    "    --------\n",
    "        Nova lista de adjacência com os valores abaixo do limiar definido.\n",
    "    \"\"\"\n",
    "    new_adj = {}\n",
    "    for i,j in adj:\n",
    "        if (adj[i,j] <= threshold):\n",
    "            new_adj[i,j] = adj[i,j]\n",
    "    return(new_adj)\n",
    "    \n",
    "def geographical_distance(adj,pos):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        adj - pares de pontos que correspondem a um ponto (série temporal) disposta no espaço geográfico da \n",
    "        bacia do rio Tamanduateí.\n",
    "        pos - índice (i,j) de cada ponto na matriz que representa o espaço geográfico.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        A distância euclidiana entre os pontos distribuídos na região analisada.\n",
    "    \"\"\"\n",
    "    geo_dist = {}\n",
    "    for i in adj:\n",
    "        a = pos[i[0]]\n",
    "        b = pos[i[1]]\n",
    "        dist = np.sqrt((a[0]-b[0])**2+(a[1]-b[1])**2)\n",
    "        geo_dist[i] = dist\n",
    "    return(geo_dist)\n",
    "\n",
    "def norm(data):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        Vetor numérico.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        Valores da vetor data entre o intervalo de 0 e 1.\n",
    "    \n",
    "    \"\"\"\n",
    "    n = []\n",
    "    max_value = max(data)\n",
    "    min_value = min(data)\n",
    "    for i in range(len(data)):\n",
    "        n.append((data[i]-min_value)/(max_value - min_value))\n",
    "    return(n)\n",
    "\n",
    "class reading():\n",
    "    \n",
    "    def files():\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Dados meteorológicos relacionados à região que compreende a bacia do rio Tamanduateí:\n",
    "            4464 arquivos em formato de matriz com 37 linhas e 36 colunas contendo a previsão de precipitação\n",
    "            para determinada região. Os valores -99 delimitam a região válida para as previsões.\n",
    "            Formato do nome: ppi-CZ-1-201501-1-0-0.txt\n",
    "                                      y   mo d h m\n",
    "            y: ano (2015)\n",
    "            mo: mês (1)\n",
    "            d: dia (1 - 31)\n",
    "            h: hora (0 - 23)  \n",
    "            m: minuto (00 - 50, a cada 10 minutos)\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        for day in range(0,31):\n",
    "            for hour in range(0,24):\n",
    "                for minutes in range(0,6):\n",
    "                    data[(day*144)+(hour*6)+(minutes)] = np.genfromtxt(\"01/ppi-CZ-1-201501-\"+str(day+1)+\"-\"+str(hour)+\"-\"+str(minutes*10)+\".txt\")\n",
    "\n",
    "        return(data)\n",
    "\n",
    "    def dataValidation(data):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Matrizes retornadas pela função reading.files()\n",
    "        Returns:\n",
    "        --------\n",
    "            Array unidimensional contendo os valores válidos (excluindo os valores -99)\n",
    "            e um array contendo a posição dos dados na matriz original.\n",
    "        \"\"\"\n",
    "        new_data = {}\n",
    "        new_idxs = {}\n",
    "        aux_data = np.empty((0,0))\n",
    "        idx = np.empty((0,2))\n",
    "        for keys in range(len(data)):\n",
    "            for rows in range(len(data[keys][:,0])):\n",
    "                for columns in range(len(data[keys][0,:])):\n",
    "                    if (data[keys][rows,columns] != -99):\n",
    "                        aux_data = np.append(aux_data,data[keys][rows,columns])\n",
    "                        idx = np.append(idx,[[rows,columns]],axis=0)\n",
    "            new_data[keys] = aux_data\n",
    "            new_idxs[keys] = idx\n",
    "            aux_data = np.empty((0,0))\n",
    "            idx = np.empty((0,2))\n",
    "        \n",
    "        return(new_data,new_idxs[0])\n",
    "\n",
    "    def timeSeriesGeneration(valid_data):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Arrays unidimensionais contendo os valores estimados das previsões\n",
    "        Returns:\n",
    "        --------\n",
    "            Série temporal associada a cada ponto válido (diferente de -99).\n",
    "            A série temporal 0 será composta por todos os valores na posição 0 dos 4464 arrays, e assim\n",
    "            em diante. O resultado são 587 séries temporais de tamanho 4464.\n",
    "        \"\"\"\n",
    "        time_series = {}\n",
    "        new_data = np.empty((0,0))\n",
    "        for time in range(len(valid_data[0])):\n",
    "            for data in range(len(valid_data)):\n",
    "                new_data = np.append(new_data,valid_data[data][time])\n",
    "            time_series[time] = new_data\n",
    "            new_data = np.empty((0,0))\n",
    "        \n",
    "        return(time_series)\n",
    "\n",
    "class network():\n",
    "    \n",
    "    def geo_graph(adj):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        \"\"\"\n",
    "        geo_graph = igraph.Graph()\n",
    "        geo_graph.add_vertices(587) # Número de séries temporais\n",
    "        for i in range(geo_graph.vcount()):\n",
    "            geo_graph.vs[i][\"label\"] = i # Enumerando os nós de 0 a 586\n",
    "        geo_graph.add_edges(adj)\n",
    "\n",
    "    def graphs(data):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Lista de valores inteiros que correspondem aos nós de uma rede. Os valores devem ser conectados\n",
    "            em sequência.\n",
    "            Exemplo:\n",
    "                data = (1,2,8,4,5,2,7,9,4)\n",
    "                adjacency_list from data: (1,2),(2,8),(8,4),(4,5),(5,2),(2,7),(7,9),(9,4)\n",
    "            Assim, um grafo seria construído usando o conjunto data como os nós da rede e o conjunto\n",
    "            adjacency_list seria responsável pela conexão dos nós.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "            graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            graph_degree - Array contendo o degree de cada nó da rede.\n",
    "            graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "            graph_closeness - Array contendo o closeness de cada nó da rede.\n",
    "        \"\"\"\n",
    "\n",
    "        # Graph creation from decimal integer array\n",
    "\n",
    "        graph = igraph.Graph()\n",
    "\n",
    "        #graph.add_vertices(max(data)+1)\n",
    "        graph.add_vertices(len(data))\n",
    "\n",
    "        #adjacency_list = np.empty((0,0), int)\n",
    "        aux_list = []\n",
    "        adjacency_list = []\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if not(len(data)-1 == i):\n",
    "                aux_list.append([data[i],data[i+1]])\n",
    "\n",
    "        for i,j in aux_list:\n",
    "            if not (([i,j] in adjacency_list) or ([j,i] in adjacency_list) or (i == j)):\n",
    "                adjacency_list.append([i,j])\n",
    "\n",
    "        #for i in range(max(data)+1):\n",
    "        for i in range(len(data)):\n",
    "            graph.vs[i][\"label\"] = i\n",
    "\n",
    "        graph.add_edges(adjacency_list) # Full graph, with disconnected nodes\n",
    "\n",
    "        # Only nodes with degree > 0\n",
    "\n",
    "        disconnected = np.empty((0,0), int)\n",
    "        for i in range(graph.vcount()):\n",
    "            if (graph.vs[i].degree() == 0):\n",
    "                disconnected = np.append(disconnected, i)\n",
    "\n",
    "        graph.delete_vertices(disconnected)\n",
    "        \n",
    "        graph_metrics,graph_degree,graph_betweenness,graph_closeness = network.metrics(graph)\n",
    "        \n",
    "        return(graph_metrics,graph_degree,graph_betweenness,graph_closeness)\n",
    "        \n",
    "    def metrics(g):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Grafo criado na biblioteca igraph\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            graph_degree - Array contendo o degree de cada nó da rede.\n",
    "            graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "            graph_closeness - Array contendo o closeness de cada nó da rede.            \n",
    "        \"\"\"\n",
    "\n",
    "        # Degree and Average Degree\n",
    "        degree_sequence = [round(i,4) for i in g.degree()]\n",
    "        avg_degree = round((sum(degree_sequence)/len(degree_sequence)),4)\n",
    "\n",
    "        # Diameter\n",
    "        diameter = round(g.diameter(),4)\n",
    "\n",
    "        # Betweenness and Average Betweenness\n",
    "        betweenness_sequence = [round(i,4) for i in g.betweenness()]\n",
    "        avg_betweenness = round((sum(betweenness_sequence)/len(betweenness_sequence)),4)\n",
    "\n",
    "        # Closeness and Average Closeness\n",
    "        closeness_sequence = [round(i,4) for i in g.closeness()]\n",
    "        avg_closeness = round(sum(closeness_sequence)/len(closeness_sequence),4)\n",
    "\n",
    "        # Density\n",
    "        density = round(g.density(),4)\n",
    "\n",
    "        metrics_dict = {\n",
    "            'Avg_Betweenness': avg_betweenness,\n",
    "            'Avg_Closeness': avg_closeness,\n",
    "            'Avg_Degree': avg_degree,\n",
    "            'Density': density,\n",
    "            'Diameter': diameter\n",
    "        }\n",
    "\n",
    "        return(metrics_dict,degree_sequence,betweenness_sequence,closeness_sequence)\n",
    "\n",
    "class algorithms():\n",
    "    \n",
    "    def DCSD(time_series,n): # Dynamical Characterization with Symbolic Dynamics - DCSD\n",
    "        '''\n",
    "        Parameters:\n",
    "        -----------\n",
    "            time_series - Série temporal a ser convertida em grafo.\n",
    "            n - tamanho da palavra binária usada na conversão binário/decimal\n",
    "            \n",
    "            Exemplo de aplicação do algoritmo:\n",
    "                1. Definir o valor máximo e mínimo de uma série temporal:\n",
    "                    1.1. x = [5,8,9,12,10,7,4,3,5,7,11]\n",
    "                    1.2. Max: 12\n",
    "                         Min: 3\n",
    "                2. Definir o centro da série temporal:\n",
    "                    2.1. centro: (12+3)/2 = 7.5\n",
    "                3. Gerar um array binário (b), tal como se segue:\n",
    "                    3.1. x(i) >= centro, então b(i) = 1\n",
    "                    3.2. x(i) < centro, então b(i) = 0\n",
    "                    3.3. b = [0,1,1,1,1,0,0,0,0,0,1]\n",
    "                4. Conversão da série binária em uma série decimal:\n",
    "                    4.1. A conversão será feita através de palavras binárias de tamanho N.\n",
    "                    4.2. O grupamento de tamanho 4 terá um comportamento deslizante, sempre com um passo\n",
    "                    à direita:\n",
    "                        4.2.1. Assumindo N = 4:\n",
    "                                [|0,1,1,1|,1,0,0,0,0,0,1]\n",
    "                                     7\n",
    "                                [0,|1,1,1,1|,0,0,0,0,0,1]\n",
    "                                       15\n",
    "                                [0,1,|1,1,1,0|,0,0,0,0,1]\n",
    "                                         14\n",
    "                                [0,1,1,|1,1,0,0|,0,0,0,1]\n",
    "                                          12\n",
    "                                [0,1,1,1,|1,0,0,0|,0,0,1]\n",
    "                                             8\n",
    "                                [0,1,1,1,1,|0,0,0,0|,0,1]\n",
    "                                               0\n",
    "                                [0,1,1,1,1,0,|0,0,0,0|,1]\n",
    "                                                 0\n",
    "                                [0,1,1,1,1,0,0,|0,0,0,1|]\n",
    "                                                   1\n",
    "\n",
    "                                Nova série decimal inteira = [7,15,14,12,8,0,0,1]\n",
    "\n",
    "                5. Cada valor da nova série gerada corresponde a um nó e a conexão entre esses nós se dá\n",
    "                através da sequência dos valores, como se segue: (7,15), (15,14), (14,12), e assim por diante.\n",
    "            \n",
    "            Returns:\n",
    "            --------\n",
    "                graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "                average closeness, density e diameter.\n",
    "                graph_degree - Array contendo o degree de cada nó da rede.\n",
    "                graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "                graph_closeness - Array contendo o closeness de cada nó da rede.\n",
    "\n",
    "            References:\n",
    "            -----------\n",
    "                FREITAS, Vander LS; LACERDA, Juliana C.; MACAU, Elbert EN.\n",
    "                Complex Networks Approach for Dynamical Characterization of Nonlinear Systems.\n",
    "                International Journal of Bifurcation and Chaos, v. 29, n. 13, p. 1950188, 2019.\n",
    "            '''\n",
    "        center = (max(time_series)+min(time_series))/2\n",
    "\n",
    "        # Converting time_series to binary\n",
    "\n",
    "        binary_array = np.empty((0,0), int)\n",
    "\n",
    "        for i in time_series:\n",
    "            if i >= center:\n",
    "                binary_array = np.append(binary_array,1)\n",
    "            else:\n",
    "                binary_array = np.append(binary_array,0)\n",
    "\n",
    "        # Converting the binary array to decimal (integer)\n",
    "\n",
    "        decimal_array = np.empty((0,0), int)\n",
    "\n",
    "        for i in range(len(binary_array)-n+1): \n",
    "            word = binary_array[i:i+n]\n",
    "            string_word = ''\n",
    "            for j in range(len(word)): \n",
    "                string_word = string_word + str(word[j])\n",
    "            # Converting to decimal\n",
    "            decimal_number = int(string_word,2)\n",
    "            decimal_array = np.append(decimal_array,decimal_number)     \n",
    "\n",
    "        graph_metrics_DCSD,graph_degree_DCSD,graph_betweenness_DCSD,graph_closeness_DCSD = network.graphs(decimal_array)\n",
    "\n",
    "        return(graph_metrics_DCSD,graph_degree_DCSD,graph_betweenness_DCSD,graph_closeness_DCSD)\n",
    "\n",
    "    def DCTIF(time_series, n): # Dynamical Characterization with Top Integral Function - DCTIF\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            time_series - Série temporal a ser convertida em grafo.\n",
    "            n - Tamanho do intervalo em que os dados serão mapeados.            \n",
    "            Exemplo:\n",
    "                1. A função DCTIF é definida como: Yk = [N · xk ] = min{i ∈ Z | N · xk ≤ i}\n",
    "                    1.1. Exemplo: x = [0.467, 1.0, 0.933, 0.8, 0.533, 0.0, 0.0, 0.067, 0.0]\n",
    "                    1.2. Usando N = 5\n",
    "                    1.3. Yk[0] = min{i ∈ Z | 5 · 0.467 ≤ i} = min{i ∈ Z | 2.335 ≤ i} = 3\n",
    "                    1.4. Yk = [3,5,5,4,3,1,1,1,1]\n",
    "                    1.5. Cada valor da nova série gerada corresponde a um nó e a conexão entre eles se dá\n",
    "                    através da sequência dos valores, como se segue: (3,5), (5,5), (5,4), e assim em diante.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            graph_degree - Array contendo o degree de cada nó da rede.\n",
    "            graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "            graph_closeness - Array contendo o closeness de cada nó da rede. \n",
    "            \n",
    "        References:\n",
    "        -----------\n",
    "            FREITAS, Vander LS; LACERDA, Juliana C.; MACAU, Elbert EN.\n",
    "            Complex Networks Approach for Dynamical Characterization of Nonlinear Systems.\n",
    "            International Journal of Bifurcation and Chaos, v. 29, n. 13, p. 1950188, 2019.\n",
    "        \"\"\"\n",
    "        # Normalizing the data\n",
    "        time_series_normalized = np.empty((0,0), float)\n",
    "        for i in time_series:\n",
    "            time_series_normalized = np.append(time_series_normalized, ((i-min(time_series))/(max(time_series)-min(time_series))))    \n",
    "\n",
    "        nodes_array = np.empty((0,0),int)\n",
    "        for i in time_series_normalized:\n",
    "            if (i*n == 0):\n",
    "                nodes_array = np.append(nodes_array,int(1))\n",
    "            elif (round(i*n) - i*n >= 0.0):\n",
    "                nodes_array = np.append(nodes_array,int(round(i*n)))\n",
    "            else:\n",
    "                nodes_array = np.append(nodes_array,int(round(i*n) + 1.0))\n",
    "\n",
    "        graph_metrics_DCTIF,graph_degree_DCTIF,graph_betweenness_DCTIF,graph_closeness_DCTIF = network.graphs(nodes_array)\n",
    "\n",
    "        return(graph_metrics_DCTIF,graph_degree_DCTIF,graph_betweenness_DCTIF,graph_closeness_DCTIF)\n",
    "\n",
    "    def VG(time_series):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Uma série temporal que será transformada em um grafo do tipo natural visibility graph. Cada ponto\n",
    "            da série será convertido em um nó, sendo que a conexão entre os nós é definida de acordo com um \n",
    "            critério de visibilidade.\n",
    "            Exemplo:\n",
    "                Critério de visibilidade: yc < yb + (ya - yb)*((tb - tc)/(tb - ta))\n",
    "                    Dois pontos quaisquer em uma série temporal, (ya,ta) e (yb,tb), serão conectados no grafo,\n",
    "                    se, e somente se, um terceiro ponto, (yc,tc), colocado entre eles for capaz de satisfazer\n",
    "                    o critério de visibilidade.\n",
    "                y = [5,8,9,12,10,7,4,3,5,7,11]\n",
    "                t = [0,1,2,3,4,5,6,7,8,9,10] -> eixo temporal \n",
    "                Avaliando os pontos ya = 5 e yb = 8:\n",
    "                - Não há pontos intermediários, yc = 0\n",
    "                - Critério:\n",
    "                    0 < 8 + (5-8)*((1-0)/(1-0))\n",
    "                    0 < 8 + (-3)*1 \n",
    "                    0 < 5\n",
    "                    Logo, os pontos 5 e 8 serão conectados.\n",
    "                Avaliando os pontos ya = 9 e yb = 10:\n",
    "                - Ponto intermediário: yc = 12\n",
    "                - Critério:\n",
    "                    12 < 10 + (9 - 10)*((4-3)/(4-2))\n",
    "                    12 < 10 + (-1)*(1/2)\n",
    "                    12 < 10 - 1/2\n",
    "                    12 < 9.5\n",
    "                    Condição não satisfeita. Sendo assim, os pontos 9 e 10 não seriam conectados na rede.\n",
    "                \n",
    "        Returns:\n",
    "        --------\n",
    "            graph_metrics - Dicionário normalizado contendo as medidas average degree, average betweenness,\n",
    "            average closeness, density e diameter.\n",
    "            graph_degree - Array contendo o degree de cada nó da rede.\n",
    "            graph_betweenness - Array contendo o betweenness de cada nó da rede.\n",
    "            graph_closeness - Array contendo o closeness de cada nó da rede.\n",
    "\n",
    "        References:\n",
    "        -----------\n",
    "            LACASA, Lucas et al. \n",
    "            From time series to complex networks: The visibility graph.\n",
    "            Proceedings of the National Academy of Sciences, v. 105, n. 13, p. 4972-4975, 2008.\n",
    "        \"\"\"\n",
    "        vg_igraph = ts2vg.NaturalVisibilityGraph(time_series).as_igraph()\n",
    "        graph_metrics_VG,graph_degree_VG,graph_betweenness_VG,graph_closeness_VG = network.metrics(vg_igraph)\n",
    "        \n",
    "        return(graph_metrics_VG,graph_degree_VG,graph_betweenness_VG,graph_closeness_VG)\n",
    "\n",
    "class saving():\n",
    "    \n",
    "    def saving_metrics(vg_metrics,dctif_metrics,dcsd_metrics):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Dicionários contendo as métricas nonrmalizadas average degree, average betweenness, \n",
    "            average closeness,density e diameter para cada um dos três algoritmos de conversão de \n",
    "            séries temporais em grafos.\n",
    "                \n",
    "            Os dados são salvos no formato csv.\n",
    "            \n",
    "        \"\"\"\n",
    "        VG_metrics_df = pd.DataFrame(data=vg_metrics.values())\n",
    "        DCSD_metrics_df = pd.DataFrame(data=dcsd_metrics.values())\n",
    "        DCTIF_metrics_df = pd.DataFrame(data=dctif_metrics.values())\n",
    "\n",
    "        VG_metrics_df.to_csv('VG-metrics.csv',index=False)\n",
    "        DCSD_metrics_df.to_csv('DCSD-metrics.csv',index=False)\n",
    "        DCTIF_metrics_df.to_csv('DCTIF-metrics.csv',index=False)\n",
    "\n",
    "        \n",
    "    def saving_degree(vg_degree,dctif_degree,dcsd_degree):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Sequência de graus de cada grafo para os 3 algoritmos testados.\n",
    "               \n",
    "            Os dados são salvos no formato csv.\n",
    "        \"\"\"\n",
    "        for i in range(587):\n",
    "            if (len(dcsd_degree[i]) != 4464):\n",
    "                for j in range((4464-len(dcsd_degree[i]))):\n",
    "                    dcsd_degree[i].append(0)\n",
    "            if (len(dctif_degree[i]) != 4464):\n",
    "                for k in range((4464-len(dctif_degree[i]))):\n",
    "                    dctif_degree[i].append(0)\n",
    "\n",
    "        VG_degrees_df = pd.DataFrame(data=vg_degree)\n",
    "        DCSD_degrees_df = pd.DataFrame(data=dcsd_degree)\n",
    "        DCTIF_degrees_df = pd.DataFrame(data=dctif_degree)\n",
    "\n",
    "        VG_degrees_df.to_csv('VG-degrees.csv',index=False)\n",
    "        DCSD_degrees_df.to_csv('DCSD-degrees.csv',index=False)\n",
    "        DCTIF_degrees_df.to_csv('DCTIF-degrees.csv',index=False)\n",
    "\n",
    "    def saving_betweenness(vg_betweenness,dctif_betweenness,dcsd_betweenness):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Sequência dos valores de betweenness de cada grafo para os 3 algoritmos testados.\n",
    "                \n",
    "            Os dados são salvos no formato csv.\n",
    "        \"\"\"\n",
    "        for i in range(587):\n",
    "            if (len(dcsd_betweenness[i]) != 4464):\n",
    "                for j in range((4464-len(dcsd_betweenness[i]))):\n",
    "                    dcsd_betweenness[i].append(0)\n",
    "            if (len(dctif_betweenness[i]) != 4464):\n",
    "                for k in range((4464-len(dctif_betweenness[i]))):\n",
    "                    dctif_betweenness[i].append(0)\n",
    "\n",
    "        vg_betweenness_df = pd.DataFrame(data=vg_betweenness)\n",
    "        dcsd_betweenness_df = pd.DataFrame(data=dcsd_betweenness)\n",
    "        dctif_betweenness_df = pd.DataFrame(data=dctif_betweenness)\n",
    "\n",
    "        vg_betweenness_df.to_csv('VG-betweenness.csv',index=False)\n",
    "        dcsd_betweenness_df.to_csv('DCSD-betweenness.csv',index=False)\n",
    "        dctif_betweenness_df.to_csv('DCTIF-betweenness.csv',index=False)\n",
    "        \n",
    "    def saving_closeness(vg_closeness,dctif_closeness,dcsd_closeness):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Sequência dos valores de closeness de cada grafo para os 3 algoritmos testados.\n",
    "                \n",
    "            Os dados são salvos no formato csv.\n",
    "        \"\"\"\n",
    "        for i in range(587):\n",
    "            if (len(dcsd_closeness[i]) != 4464):\n",
    "                for j in range((4464-len(dcsd_closeness[i]))):\n",
    "                    dcsd_closeness[i].append(0)\n",
    "            if (len(dctif_closeness[i]) != 4464):\n",
    "                for k in range((4464-len(dctif_closeness[i]))):\n",
    "                    dctif_closeness[i].append(0)\n",
    "\n",
    "        vg_closeness_df = pd.DataFrame(data=vg_closeness)\n",
    "        dcsd_closeness_df = pd.DataFrame(data=dcsd_closeness)\n",
    "        dctif_closeness_df = pd.DataFrame(data=dctif_closeness)\n",
    "\n",
    "        vg_closeness_df.to_csv('VG-closeness.csv',index=False)\n",
    "        dcsd_closeness_df.to_csv('DCSD-closeness.csv',index=False)\n",
    "        dctif_closeness_df.to_csv('DCTIF-closeness.csv',index=False)\n",
    "\n",
    "        \n",
    "class comparing():\n",
    "    \n",
    "    def __init__(self, graph_metrics):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            Array de métricas que será usado como parâmetro para o restante das funções dessa classe.\n",
    "            São recebidos tanto os feature arrays, com métricas combinadas, quanto os sequence arrays, como é\n",
    "            o caso da sequência de graus.\n",
    "            As métricas enviadas são as pertencentes a todos os grafos. Sendo assim, self.metrics_array\n",
    "            receberá um array de tamanho 587, onde cada posição terá um array de métricas correspondente a\n",
    "            um grafo.\n",
    "            As funções de distância/similaridade irão computar a medida entre todos os pares (a,b) de métricas,\n",
    "            com a e b variando de 0 até 586, apenas desconsiderando casos como: \n",
    "                - a = b\n",
    "                - (b,a) se já existir um valor calculado para o par (a,b)\n",
    "        \"\"\"\n",
    "        self.metrics_array = graph_metrics\n",
    "    \n",
    "    def jensenshannon(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Jensen-Shannon, no formato de um dicionário, entre todos os \n",
    "            pares de grafos.\n",
    "            A função computa a raiz quadrada da divergência de Jensen-Shannon:\n",
    "                JSD(P||Q) = ((D(P||M) + D(Q||M))/2)^(1/2)\n",
    "                Onde:\n",
    "                    D é a divergência de Kullback-Leibler \n",
    "                    M = (P + Q)/2 \n",
    "        \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2205.\n",
    "                \n",
    "        \"\"\"\n",
    "        jensenshannon_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                jensenshannon_dist[i,j] = distance.jensenshannon(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(jensenshannon_dist)    \n",
    "    \n",
    "    \n",
    "    def euclidean(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância Euclidiana, no formato de um dicionário, entre todos os \n",
    "            pares de grafos.\n",
    "            Considerando os vetores, a e b, a distância euclidiana é calculada como:\n",
    "                e_dist(a,b) = ||a - b||\n",
    "        \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2204-2205.\n",
    "            \n",
    "        \"\"\"\n",
    "        euclidean_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                euclidean_dist[i,j] = distance.euclidean(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(euclidean_dist)\n",
    "\n",
    "    def manhattan(self):\n",
    "        \"\"\"    \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Manhattan (Cityblock), no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, a distância de manhattan é calculada como:\n",
    "                m_dist(a,b) = Σ(|ai - bi|)\n",
    "                i deve ser iterado a fim de percorrer todos os elementos de cada vetor.\n",
    "\n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2203.\n",
    "        \"\"\"\n",
    "        manhattan_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                manhattan_dist[i,j] = distance.cityblock(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(manhattan_dist)\n",
    "\n",
    "    def canberra(self):\n",
    "        \"\"\"   \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância de Canberra, no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, a distância de canberra é calculada como:\n",
    "                c_dist(a,b) = Σ((|ai - bi|)/(|ai|+|bi|))\n",
    "                i deve ser iterado a fim de percorrer todos os elementos de cada vetor\n",
    "\n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2202.\n",
    "        \"\"\"\n",
    "        canberra_dist = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                canberra_dist[i,j] = distance.canberra(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(canberra_dist)\n",
    "\n",
    "    def cosine(self):\n",
    "        \"\"\"    \n",
    "        Returns:\n",
    "        --------\n",
    "            Retorna a o valor da distância baseada em cosseno, no formato de um dicionário, entre \n",
    "            todos os pares de grafos.\n",
    "            Considerando os vetores a e b, o cosseno entre esses dois vetores pode ser obtido pela\n",
    "            seguinte relação:\n",
    "                cos(θ) = (a·b)/(||a||*||b||)\n",
    "                cos_dist = 1 - cos(θ)\n",
    "\n",
    "                (a·b) é o produto escalar entre os dois vetores.\n",
    "                \n",
    "        Reference:\n",
    "        ----------\n",
    "            SciPy community. SciPy Reference Guide. <https://docs.scipy.org/doc/scipy/scipy-ref-1.5.4.pdf>, \n",
    "            v. 1.5.4, p. 2204.\n",
    "        \"\"\"\n",
    "        cosine_sim = {}\n",
    "        ctrl = 1\n",
    "        for i in range(len(self.metrics_array)):\n",
    "            for j in range(ctrl,len(self.metrics_array)):\n",
    "                cosine_sim[i,j] = distance.cosine(self.metrics_array[i],self.metrics_array[j])\n",
    "            ctrl += 1\n",
    "        return(cosine_sim)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading files and time series generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.618616342544556\n"
     ]
    }
   ],
   "source": [
    "# Estimated execution time: 64,39s\n",
    "init = time.time()\n",
    "\n",
    "# Time series\n",
    "files = reading.files()\n",
    "validated_files,position = reading.dataValidation(files) # removing -99 values\n",
    "meteorological_time_series = reading.timeSeriesGeneration(validated_files)\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estimated execution time: 5357,62s\n",
    "init = time.time()\n",
    "\n",
    "vg_metrics = {}\n",
    "vg_degree = {}\n",
    "vg_betweenness = {}\n",
    "vg_closeness = {}\n",
    "\n",
    "dctif_metrics = {}\n",
    "dctif_degree = {}\n",
    "dctif_betweenness = {}\n",
    "dctif_closeness = {}\n",
    "\n",
    "dcsd_metrics = {}\n",
    "dcsd_degree = {}\n",
    "dcsd_betweenness = {}\n",
    "dcsd_closeness = {}\n",
    "\n",
    "for idx in range(len(meteorological_time_series)):\n",
    "    print(idx,\"de\",(len(meteorological_time_series)-1))\n",
    "    vg_metrics[idx],vg_degree[idx],vg_betweenness[idx],vg_closeness[idx] = algorithms.VG(meteorological_time_series[idx])\n",
    "    dcsd_metrics[idx],dcsd_degree[idx],dcsd_betweenness[idx],dcsd_closeness[idx] = algorithms.DCSD(meteorological_time_series[idx],10)\n",
    "    dctif_metrics[idx],dctif_degree[idx],dctif_betweenness[idx],dctif_closeness[idx] = algorithms.DCTIF(meteorological_time_series[idx],50)\n",
    "    \n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.807220697402954\n"
     ]
    }
   ],
   "source": [
    "# Estimated excecution time: 18,96s\n",
    "init = time.time()\n",
    "\n",
    "saving.saving_metrics(vg_metrics,dctif_metrics,dcsd_metrics)\n",
    "saving.saving_degree(vg_degree,dctif_degree,dcsd_degree)\n",
    "saving.saving_betweenness(vg_betweenness,dctif_betweenness,dcsd_betweenness)\n",
    "saving.saving_closeness(vg_closeness,dctif_closeness,dcsd_closeness)\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando as distâncias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility Graphs - VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.66877150535583\n"
     ]
    }
   ],
   "source": [
    "# VG\n",
    "# Tempo de execução: 115s\n",
    "init = time.time()\n",
    "\n",
    "vg_metrics_df = pd.read_csv(\"VG-metrics.csv\") # Cada linha do DataFrame é um vetor de características\n",
    "vg_degrees_df = pd.read_csv(\"VG-degrees.csv\") # Cada coluna representa a distribuição de graus de uma rede\n",
    "vg_betweenness_df = pd.read_csv(\"VG-betweenness.csv\") # Cada coluna representa a distribuição de betweenness de uma rede\n",
    "vg_closeness_df = pd.read_csv(\"VG-closeness.csv\") # Cada coluna representa a distribuição de closeness de uma rede\n",
    "\n",
    "vg_metrics_array = vg_metrics_df.to_numpy() # Cada posição do array possui um vetor de características\n",
    "vg_degrees_array = vg_degrees_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de graus\n",
    "vg_betweenness_array = vg_betweenness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de betweenness\n",
    "vg_closeness_array = vg_closeness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de closeness\n",
    "\n",
    "# Calculando as métricas entre todos os vetores de características.\n",
    "\n",
    "dist_vg_metrics = comparing(vg_metrics_array)\n",
    "\n",
    "\n",
    "euclidean_dist_vg_metrics = dist_vg_metrics.euclidean() # Não é capaz de captar correlação\n",
    "manhattan_dist_vg_metrics = dist_vg_metrics.manhattan() # Não é capaz de captar correlação\n",
    "canberra_dist_vg_metrics = dist_vg_metrics.canberra() # Não é capaz de captar correlação\n",
    "cosine_dist_vg_metrics = dist_vg_metrics.cosine() # Não é capaz de captar correlação\n",
    "jensenshannon_dist_vg_metrics = dist_vg_metrics.jensenshannon() # Não é capaz de captar correlação \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com distribuição de graus.\n",
    "\n",
    "dist_vg_degrees = comparing(vg_degrees_array)\n",
    "\n",
    "euclidean_dist_vg_degrees = dist_vg_degrees.euclidean() # Há correlação, mas a definição do limiar é problemática\n",
    "manhattan_dist_vg_degrees = dist_vg_degrees.manhattan() # Limiar consistente. Teste em: <18000\n",
    "canberra_dist_vg_degrees = dist_vg_degrees.canberra() # Limiar pouco consistente. Teste em: <330\n",
    "cosine_dist_vg_degrees = dist_vg_degrees.cosine() # Limiar consistente. Teste em: <0.27\n",
    "jensenshannon_dist_vg_degrees = dist_vg_degrees.jensenshannon() # Limiar consistente. Teste em: <0.27\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de betweenness.\n",
    "\n",
    "dist_vg_betweenness = comparing(vg_betweenness_array)\n",
    "\n",
    "euclidean_dist_vg_betweenness = dist_vg_betweenness.euclidean() #\n",
    "manhattan_dist_vg_betweenness = dist_vg_betweenness.manhattan() # \n",
    "canberra_dist_vg_betweenness = dist_vg_betweenness.canberra() # \n",
    "cosine_dist_vg_betweenness = dist_vg_betweenness.cosine() # \n",
    "jensenshannon_dist_vg_betweenness = dist_vg_betweenness.jensenshannon() #\n",
    "\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de closeness.\n",
    "\n",
    "dist_vg_closeness = comparing(vg_closeness_array)\n",
    "\n",
    "euclidean_dist_vg_closeness = dist_vg_closeness.euclidean() # \n",
    "manhattan_dist_vg_closeness = dist_vg_closeness.manhattan() #\n",
    "canberra_dist_vg_closeness = dist_vg_closeness.canberra() #\n",
    "cosine_dist_vg_closeness = dist_vg_closeness.cosine() # \n",
    "jensenshannon_dist_vg_closeness = dist_vg_closeness.jensenshannon() # \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Characterization using Symbolic Dynamics - DCSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.64785528182983\n"
     ]
    }
   ],
   "source": [
    "# DCSD\n",
    "# Tempo de execução: 177s\n",
    "init = time.time()\n",
    "\n",
    "dcsd_metrics_df = pd.read_csv(\"DCSD-metrics.csv\") # Cada linha do DataFrame é um vetor de características\n",
    "dcsd_degrees_df = pd.read_csv(\"DCSD-degrees.csv\") # Cada coluna representa a distribuição de graus de uma rede\n",
    "dcsd_betweenness_df = pd.read_csv(\"DCSD-betweenness.csv\") # Cada coluna representa a distribuição de betweenness de uma rede\n",
    "dcsd_closeness_df = pd.read_csv(\"DCSD-closeness.csv\") # Cada coluna representa a distribuição de closeness de uma rede\n",
    "\n",
    "dcsd_metrics_array = dcsd_metrics_df.to_numpy() # Cada posição do array possui um vetor de características\n",
    "dcsd_degrees_array = dcsd_degrees_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de graus\n",
    "dcsd_betweenness_array = dcsd_betweenness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de betweenness\n",
    "dcsd_closeness_array = dcsd_closeness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de closeness\n",
    "\n",
    "# Calculando as métricas entre todos os vetores de características.\n",
    "\n",
    "dist_dcsd_metrics = comparing(dcsd_metrics_array)\n",
    "\n",
    "\n",
    "euclidean_dist_dcsd_metrics = dist_dcsd_metrics.euclidean() # \n",
    "manhattan_dist_dcsd_metrics = dist_dcsd_metrics.manhattan() # \n",
    "canberra_dist_dcsd_metrics = dist_dcsd_metrics.canberra() # \n",
    "cosine_dist_dcsd_metrics = dist_dcsd_metrics.cosine() # \n",
    "jensenshannon_dist_dcsd_metrics = dist_dcsd_metrics.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com distribuição de graus.\n",
    "\n",
    "dist_dcsd_degrees = comparing(dcsd_degrees_array)\n",
    "\n",
    "euclidean_dist_dcsd_degrees = dist_dcsd_degrees.euclidean() # \n",
    "manhattan_dist_dcsd_degrees = dist_dcsd_degrees.manhattan() # \n",
    "canberra_dist_dcsd_degrees = dist_dcsd_degrees.canberra() # \n",
    "cosine_dist_dcsd_degrees = dist_dcsd_degrees.cosine() # \n",
    "jensenshannon_dist_dcsd_degrees = dist_dcsd_degrees.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de betweenness.\n",
    "\n",
    "dist_dcsd_betweenness = comparing(dcsd_betweenness_array)\n",
    "\n",
    "euclidean_dist_dcsd_betweenness = dist_dcsd_betweenness.euclidean() #\n",
    "manhattan_dist_dcsd_betweenness = dist_dcsd_betweenness.manhattan() # \n",
    "canberra_dist_dcsd_betweenness = dist_dcsd_betweenness.canberra() # \n",
    "cosine_dist_dcsd_betweenness = dist_dcsd_betweenness.cosine() # \n",
    "jensenshannon_dist_dcsd_betweenness = dist_dcsd_betweenness.jensenshannon() #\n",
    "\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de closeness.\n",
    "\n",
    "dist_dcsd_closeness = comparing(dcsd_closeness_array)\n",
    "\n",
    "euclidean_dist_dcsd_closeness = dist_dcsd_closeness.euclidean() # \n",
    "manhattan_dist_dcsd_closeness = dist_dcsd_closeness.manhattan() #\n",
    "canberra_dist_dcsd_closeness = dist_dcsd_closeness.canberra() #\n",
    "cosine_dist_dcsd_closeness = dist_dcsd_closeness.cosine() # \n",
    "jensenshannon_dist_dcsd_closeness = dist_dcsd_closeness.jensenshannon() # \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Characterization using Top Integral Function - DCTIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.17093443870544\n"
     ]
    }
   ],
   "source": [
    "# DCTIF\n",
    "# Tempo de execução: 159s\n",
    "init = time.time()\n",
    "\n",
    "dctif_metrics_df = pd.read_csv(\"DCTIF-metrics.csv\") # Cada linha do DataFrame é um vetor de características\n",
    "dctif_degrees_df = pd.read_csv(\"DCTIF-degrees.csv\") # Cada coluna representa a distribuição de graus de uma rede\n",
    "dctif_betweenness_df = pd.read_csv(\"DCTIF-betweenness.csv\") # Cada coluna representa a distribuição de betweenness de uma rede\n",
    "dctif_closeness_df = pd.read_csv(\"DCTIF-closeness.csv\") # Cada coluna representa a distribuição de closeness de uma rede\n",
    "\n",
    "dctif_metrics_array = dctif_metrics_df.to_numpy() # Cada posição do array possui um vetor de características\n",
    "dctif_degrees_array = dctif_degrees_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de graus\n",
    "dctif_betweenness_array = dctif_betweenness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de betweenness\n",
    "dctif_closeness_array = dctif_closeness_df.T.to_numpy() # Cada posição do array guarda o vetor com a distribuição de closeness\n",
    "\n",
    "# Calculando as métricas entre todos os vetores de características.\n",
    "\n",
    "dist_dctif_metrics = comparing(dctif_metrics_array)\n",
    "\n",
    "\n",
    "euclidean_dist_dctif_metrics = dist_dctif_metrics.euclidean() # \n",
    "manhattan_dist_dctif_metrics = dist_dctif_metrics.manhattan() # \n",
    "canberra_dist_dctif_metrics = dist_dctif_metrics.canberra() # \n",
    "cosine_dist_dctif_metrics = dist_dctif_metrics.cosine() # \n",
    "jensenshannon_dist_dctif_metrics = dist_dctif_metrics.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com distribuição de graus.\n",
    "\n",
    "dist_dctif_degrees = comparing(dctif_degrees_array)\n",
    "\n",
    "euclidean_dist_dctif_degrees = dist_dctif_degrees.euclidean() # \n",
    "manhattan_dist_dctif_degrees = dist_dctif_degrees.manhattan() # \n",
    "canberra_dist_dctif_degrees = dist_dctif_degrees.canberra() # \n",
    "cosine_dist_dctif_degrees = dist_dctif_degrees.cosine() # \n",
    "jensenshannon_dist_dctif_degrees = dist_dctif_degrees.jensenshannon() # \n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de betweenness.\n",
    "\n",
    "dist_dctif_betweenness = comparing(dctif_betweenness_array)\n",
    "\n",
    "euclidean_dist_dctif_betweenness = dist_dctif_betweenness.euclidean() #\n",
    "manhattan_dist_dctif_betweenness = dist_dctif_betweenness.manhattan() # \n",
    "canberra_dist_dctif_betweenness = dist_dctif_betweenness.canberra() # \n",
    "cosine_dist_dctif_betweenness = dist_dctif_betweenness.cosine() # \n",
    "jensenshannon_dist_dctif_betweenness = dist_dctif_betweenness.jensenshannon() #\n",
    "\n",
    "\n",
    "# Calculando as métricas entre todos os vetores com a sequência de closeness.\n",
    "\n",
    "dist_dctif_closeness = comparing(dctif_closeness_array)\n",
    "\n",
    "euclidean_dist_dctif_closeness = dist_dctif_closeness.euclidean() # \n",
    "manhattan_dist_dctif_closeness = dist_dctif_closeness.manhattan() #\n",
    "canberra_dist_dctif_closeness = dist_dctif_closeness.canberra() #\n",
    "cosine_dist_dctif_closeness = dist_dctif_closeness.cosine() # \n",
    "jensenshannon_dist_dctif_closeness = dist_dctif_closeness.jensenshannon() # \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end-init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
